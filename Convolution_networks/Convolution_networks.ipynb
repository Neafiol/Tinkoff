{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xoYxNdJMghf_"
   },
   "source": [
    "## Свёрточные сети\n",
    "\n",
    "Сегодня мы детальнее поговорим про общие подходы при обучении нейросетей, и что происходит внутри них.\n",
    "\n",
    "<img width='400px' src='https://raw.githubusercontent.com/sslotin/universum-dl/43390d26d5f256dcc68a6ba51998bd626b3f6d33/images/cat.png'>\n",
    "\n",
    "Если попытаться визуализировать то, что выучивает каждый нейрон в нейросети (например, посмотрев, какие входные пиксели на него сильнее всего влияют), то можно увидеть, что чем глубже находится слой, тем более абстрактные фичи он содержит.\n",
    "\n",
    "Например, в сетях для распознавания картинок первые слои учатся обнаруживать геометрические примитивы: линии, границы, углы. Следующий слой может распознавать простые геометрические фигуры. Следующий распознаёт наличие целых объектов и т. д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FkwZ7FVKghgG"
   },
   "source": [
    "**Weight sharing**. [Эксперименты с дропаутом](https://arxiv.org/abs/1701.05369) показывают, что в линейном слое примерно 99% весов на самом деле можно выкинуть. Логично, что в оптимальной архитектуре не должно быть бесполезных весов — лишние параметры всегда ведут к переобучению. В случае с картинками решение в том, чтобы использовать информацию о расположении пикселей относительно друг друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GAid3Pt_ghgL"
   },
   "source": [
    "## Свёртки и пуллинги\n",
    "\n",
    "**Как хранятся картинки**. Когда говорят «изображение», представляйте не прямоугольник, а параллелепипед, высотой которого будет размер каналов. Например, обычные цветные RGB картинки имеют 3 канала: на красный (R), зелёный (G) и синий (B).\n",
    "\n",
    "0. Введем такую функцию, как **ядро** (англ. **kernel**) — она считает скалярное произведение вектора-входа со своим вектором-параметром.\n",
    "1. Разобьем исходный паралеллелепипед на сколько-то параллелепипедов одинакового размера вдоль размерности, соответствующей каналам. Они могут пересекаться.\n",
    "2. Каждый из них «разгладим» в вектор.\n",
    "3. К кажому такому вектору и применим по очереди каждый кернел (их обычно берут много разных).\n",
    "4. Положим то, что получилось, в новый параллелепипед.\n",
    "5. Посчитаем для кажой ячейки какую-нибудь нелинейность. Обычно это ReLU из-за вычислительных причин.\n",
    "\n",
    "<img width='350px' src='https://raw.githubusercontent.com/sslotin/universum-dl/43390d26d5f256dcc68a6ba51998bd626b3f6d33/images/conv1.png'>\n",
    "\n",
    "Эта операция называется **свёрткой**. Помимо кернела, в ней есть другие параметры — паддинг (отступ по краям), страйды (шаги по x и y). Также свёртка может быть в 2d и 3d. Посмотрите этот репозиторий, чтобы получше разобраться со свёрточной арифметикой: https://github.com/vdumoulin/conv_arithmetic\n",
    "\n",
    "![](http://deeplearning.net/software/theano/_images/numerical_padding_strides.gif)\n",
    "\n",
    "**Пулингом** называют операцию, при которой входной тензор так же разбивается на квадраты (не паралепипеды — операция независима по каждому каналу) и на каждом квадрате считается какая-нибудь редукция (чаще всего максимум или среднее по всем значениям в квадрате), после чего полученные значения записываются на следующий слой в том же порядке.\n",
    "\n",
    "<img width='400px' src='http://cs231n.github.io/assets/cnn/maxpool.jpeg'>\n",
    "\n",
    "В свёртках переиспользуется очень много параметров: кернел для каждого фильтра (выходного канала) использует один и тот же вектор-параметр для скалярного умножения. Из-за этого каждый фильтр как правило выучивает какую-то конкретную фичу, вроде наличия какого-либо объекта на своём регионе. Пулинг используют затем для понижения размерности: каждый нейрон после свертки выражает степень уверенности, что на регионе присутствует какой-то объект, и поэтому логично в качестве вероятности наличия объекта на регионе из под-регионов использовать максимум или среднее.\n",
    "\n",
    "Чаще всего используют свёртки 3x3 со страйдом 2x2 (то есть квадраты перекрываются по 3 крайним пикселям) с пулингом размера 2x2 (не перекрываются)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIRxxfnbghgQ"
   },
   "source": [
    "## Аугментация данных\n",
    "\n",
    "Аугментацией называется процесс получения новых синтетических данных из имеющихся, чтобы подать в обучение. Это часто (особенно в компьютерном зрении) позволяет улучшить качество модели, не используя дополнительных данных.\n",
    "\n",
    "Формально, в случае с классификацией, аугментация — это любое преобразование, которое корректно изменяет данные, не меняя их класс.\n",
    "\n",
    "В случае с картинками, можно попробовать добавить следующие преобразования, которые с какой-то вероятностью будут использоваться во время обучения:\n",
    "\n",
    "* Поворот на малый угол.\n",
    "* Добавление шума.\n",
    "* Обрезание границ и последующее растяжение до исходного размера.\n",
    "* Горизонтальное отражение (но в нашем случае оно вредно).\n",
    "* Смещение на небольшое расстояние.\n",
    "\n",
    "Понятно, что лейбл эти преобразования изменить не должны.\n",
    "\n",
    "<img src='https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/a5da2c3b4174449d13dd746b7d00897c6bc1f334/5-Figure2-1.png' width='500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FvB63L55ghgV"
   },
   "source": [
    "## Взрывающийся градиент\n",
    "\n",
    "В сетях происходит очень много чего стохастического: батч формируется случайно, аугментация, рандомизированные слои вроде дропаута, вычислительные ошибки. Это всё может привести к тому, что сеть на какой-то итерации будет очень уверенна в неправильном предсказании и некоторые её параметры получат очень большой градиент. Это может привести к тому, что эти параметры «улетят» куда-то настолько далеко, и после этого сеть будет всегда предсказывать класс, который на этой итерации был правильным. \n",
    "\n",
    "Простое решение: просто обрезать градиент в случае, если градиент больше какого-то фиксированного значения. Для этого есть функция `torch.nn.utils.clip_grad_norm_`, которая принимает параметры модели и параметр `threshold`. Она считает норму (длину вектора) градиента и, если она больше `threshold`, нормирует градиенты так, чтобы она была равна `threshold`. Эта функция также возвращает само значение нормы, что может быть очень полезно при анализе обучения (например, если она становится маленькой, то, значит, сеть сходится к какому-то плато)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GbzBV6t7ghgZ"
   },
   "source": [
    "## Инициализация параметров\n",
    "\n",
    "Сначала приведем пример плохой инициализации. Пусть мы задали все значения изначально нулями. В таком случае наша модель становится эквивалентна линейной модели — производная по функции потерь одинакова для каждого $w_i$, таким образом, все веса имеют одинаковые значения и в последующей итерации, что делает нейроны в сети симметричными.\n",
    "\n",
    "Подход получше — инициализировать каждый вес случайно. Но тут нужно быть осторожным — если задать их слишком большими, то сеть может быть изначально очень уверенна в своих предсказаниях, и подвинуть параметры оттуда будет очень трудно.\n",
    "\n",
    "Решение следующее. С точки зрения слоя, ему на вход подается сэмпл из какого-то распределения, и он под это распределение подстраивается. В нейросетях размеры слоев достаточно большие, чтобы в них работали законы статистики, все разработчики фреймворках условились инициализировать веса всех слоев в предположении, что на вход подаются данные из какого-то распределения со средним 0 и дисперсией 1, и на выходе должно получиться какое-то распределение со средним тоже 0 и дисперсией 1. Чаще всего изначальные веса берут либо из нормального, либо из равномерного распределения, «обрезанного» так, чтобы дисперсия каждого выходного значения получилась единичной.\n",
    "\n",
    "Аналогично нужно поступать со входными векторными данными: нормализовывать. Это будет важно при работе с изображениями: не надо подавать на вход вектора с элементами от 0 до 255. Самое простое рабочее решение — нормализовать вход, поделив его на 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AByr2Ksqghge"
   },
   "source": [
    "## Минутка физики\n",
    "\n",
    "Потребляемая энергия в сети с переменным током в единицу времени считается по формуле\n",
    "\n",
    "$$W = CV^2f$$\n",
    "\n",
    "где $C$ это емкость сети, $V$ это напряжение, а $f$ это частота. В случае с процессорами, это именно та частота, с которой выполняются элементарные операции, например сложение.\n",
    "\n",
    "<img width='350px' src='https://i.ibb.co/yhsGRJK/Screenshot-from-2019-02-08-14-52-07.png'>\n",
    "\n",
    "Однако, если мы сделаем сеть из двух параллельно подключенных процессоров, работающих на половинной частоте, мы можем получить сеть, потребляющую ~40% изначальной энергии, делающую то же количество полезной работы — то же суммарное количество процессорных тактов:\n",
    "\n",
    "<img width='450px' src='https://i.ibb.co/WgLCxxL/Screenshot-from-2019-02-08-14-52-18.png'>\n",
    "\n",
    "Поэтому для хорошо распараллеливаемых операций используют другой тип вычислительных устройств, в которых не 4-8 быстрых (3-4 GHz) процессоров, а несколько тысяч медленных (~1GHz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fbICDdXghgj"
   },
   "source": [
    "## Device-agnostic код\n",
    "\n",
    "К любой модели или тензору в PyTorch можно применить `.cuda()` и `.cpu()`, чтобы перевести тензор на память GPU или в оперативную память соответственно. Но если мы будем писать такой код, нам будет довольно проблематично портировать его на другие машины, где, например, нет GPU (например, если вы хотите скачать тетрадку с colab к себе и запустить).\n",
    "\n",
    "Многие фреймворки позволяют абстрагироваться от устройства конкретных вычислительных устройств. В PyTorch для этого есть объект `torch.device`, который позволяет явно задавать, на каком устройстве хранить тензор или модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "PZWc8VEvghgp",
    "outputId": "fc0adcdd-94dd-4d75-e74a-c12b583b2b34"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda:0')  # используй первую GPU (номеруются с нуля)\n",
    "\n",
    "X = torch.randn(5, 100, device=device)  # создай матрицу на этом устройстве\n",
    "# альтернативно: X = X.to(device)\n",
    "\n",
    "# создадим какую-нибудь модель\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(100, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 8)\n",
    ")\n",
    "\n",
    "model = model.to(device)  # переведи параметры модели на это устройство\n",
    "\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hASWpaGEghg2"
   },
   "source": [
    "# Колоризация изображений\n",
    "\n",
    "Начнём практическую часть. Обучим autoencoder-like сеть, которая учится восстанавливать изображение по его черно-белой версии. В качестве лосса будем так же использовать какую-нибудь меру расстояния между изображениями (например, l1 или l2).\n",
    "\n",
    "Тот пайплайн, что у нас получится, с минимальными изменениями можно будет также использовать и для других подобных задач, связанных с восстановлением изображений после каких-либо необратимых преобразований, например после подмешивании шума (denoising autoencoder) или понижения размера (DeepHD).\n",
    "\n",
    "![](https://camo.githubusercontent.com/c5f95c94d70a3e52561c1d0591e84a5e3b86eb74/687474703a2f2f726963687a68616e672e6769746875622e696f2f636f6c6f72697a6174696f6e2f7265736f75726365732f696d616765732f6e65745f6469616772616d2e6a7067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKU041rBghg5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyQTRv-tghhA"
   },
   "source": [
    "Для начала скачаем данные. Годятся вообще любые изображения, не обязательно из какого-то изветсного датасета. Этой командой можно скачать и распакавать фотографии с одной школы по программированию, проходившей этим летом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qtOh57zVghhG"
   },
   "source": [
    "Есть два подхода к работе с данными:\n",
    "\n",
    "1. Сначала преобразовать все имеющиеся данные к виду, который принимает нейросеть (сразу к тензорам одинакового размера).\n",
    "2. Хранить сырые данные и преобразование препроцессинга (функцию) и собирать батчи на лету.\n",
    "\n",
    "Если это не что-то совсем простое, то второй вариант предпочтительнее, так как он не требует дополнительной памяти (датасеты могут быть большими), времени на векторизацию датасета, а так же сбор батча «на лету» позволяет там же делать аугментацию.\n",
    "\n",
    "Для этого в PyTorch есть две абстракции: `Dataset` и `DataLoader`.\n",
    "\n",
    "`Dataset` — абстрактный класс, от которого нужно отнаследовать класс датасета, который мы напишем. В нём должны быть определён конструктор (в нём обычно загружаются в память сырые данные, которые лежат где-то на диске, а также сохраняется какая-нибудь другая информация), метод `__len__` (должен вернуть размер датасета) и `__getitem__`, который должен по номеру сэмпла вернуть его в виде тензора (возможно, произведя какой-нибудь препроцессинг)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2dPQYnVghhI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, path, transform_x, transform_y):\n",
    "        self.transform_x = transform_x\n",
    "        self.transform_y = transform_y\n",
    "      \n",
    "        filenames = []\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "                if file.endswith('.jpg') or file.endswith('.JPG'):\n",
    "                    filenames.append(os.path.join(root, file))\n",
    "\n",
    "        self.images = []\n",
    "        for filename in tqdm(filenames):\n",
    "            try:\n",
    "                with Image.open(filename) as image:\n",
    "                    self.images.append(image.copy())\n",
    "            except:\n",
    "                print('Could not load image:', filename)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        Y = self.transform_y(img)\n",
    "        X = self.transform_x(Y)\n",
    "        X=X.to(torch.device('cuda:0') )\n",
    "        Y=Y.to(torch.device('cuda:0'))\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cbxuNqYNghhO"
   },
   "source": [
    "Чтобы подавать картинки на вход нейросети, нужно их перевести в тензоры, причём одинакового размера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CMi1Ts3GghhQ"
   },
   "outputs": [],
   "source": [
    "transform_all = transforms.Compose([\n",
    "    # вырежем случайный прямоугольник\n",
    "    transforms.RandomResizedCrop(128),\n",
    "    # горизонтально перевернем -- изображение останется валидным\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # что бы ещё поделать, чтобы увеличить размер датасета?\n",
    "    # ...\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def to_gray1scale(x):\n",
    "    return (1-(x[0] * 0.299 + x[1] * 0.587 + x[2] * 0.114)).view(1, 128, 128)\n",
    "    # минутка эволюционной биологии: как вы думаете, почему коэффициенты именно такие?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3LzgvoPghhV"
   },
   "source": [
    "Здесь `transform_all` и `to_grayscale` являются функциями (формально, первый является функтором), которые мы передадим дальше в `DataLoader`, который оборачивает датасет и позволяет итерироваться по нему по батчам, а также реализует разные полезные функции вроде перемешивания данных после каждой эпохи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4049
    },
    "colab_type": "code",
    "id": "LcvQ_qo6ghhX",
    "outputId": "ee05de91-c1fe-4778-f73d-afc3ac6265ff"
   },
   "outputs": [],
   "source": [
    "dataset = ColorizationDataset('universum-photos', to_grayscale, transform_all)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "QQFdr9-lxdal",
    "outputId": "b4330688-cbb8-4ea4-a486-071c40a9b296"
   },
   "outputs": [],
   "source": [
    "plt.imshow(dataset[1][0].numpy().reshape(128,128))\n",
    "# plt.imshow(dataset[12][1].transpose(0,1).transpose(1,2).numpy().reshape(128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "bYdJE2Z25BkA",
    "outputId": "f32a0e6a-1962-4a9c-8a8d-594fd2649a20"
   },
   "outputs": [],
   "source": [
    "for i , j in zip(range(3),range(3)):\n",
    "  print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6rKNmYHoghhb"
   },
   "source": [
    "**Skip-connection**. Иногда бывает полезно присоединить к выходу какого-то слоя его вход, чтобы следующий получил такую же, неизменённую копию. Здесь мы поступим именно так: подадим исходное черно-белое изображение в какую-то одну часть сети, которая сконцентрируется на определении цвета, а затем припишем последним слоем её выход и отправим дальше другому модулю, который уже раскрасит это исходное изображение. От простоты `nn.Sequential`, правда, уже придётся отказаться, и нужно написать свой класс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rs12_f0Oghhg"
   },
   "source": [
    "Глубокие сети очень часто состоят из повторяющихся блоков, отличающихся только размерностью (в данном случае — количеством фильтров). Чтобы сократить количество кода и уменьшить вероятность багов, блоки можно обернуть в одну функцию, возвращающую мини-модель из нескольких слоев. Пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfVW7hndghhd"
   },
   "outputs": [],
   "source": [
    "class Colorizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.preconcat = nn.Sequential(\n",
    "            self.BlockD(1,128),\n",
    "            self.BlockD(128,256),\n",
    "            self.BlockD(256,512),\n",
    "            self.BlockU(512,128)\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.postconcat = nn.Sequential(\n",
    "            nn.Conv2d(129, 32, (3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            #3 cganal (RGB)\n",
    "            nn.Conv2d(32, 3, (3, 3), padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def BlockD(self,channels_in, channels_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(channels_in, channels_out, (3, 3), padding=1),\n",
    "            nn.MaxPool2d((2, 2), stride=(2, 2)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def BlockU(self,channels_in, channels_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(channels_in, channels_out, (3, 3), padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.preconcat(x)\n",
    "        # исходное чб изображение -- просто дополнительным слоем\n",
    "        #size = beg_s/2/2/2*2*2*2\n",
    "        h = torch.cat((h, x), 1)\n",
    "        h = self.postconcat(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NiycKalgghho"
   },
   "source": [
    "Дальше как обычно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TV0nIXc_ghhp"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "lr = 1e-2\n",
    "device=torch.device('cuda:0')\n",
    "model = Colorizer()#\n",
    "model=model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.L1Loss()  # тут можно поиграться с лоссами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "a6JHkbOGghht",
    "outputId": "417359e4-1e0a-4646-81ae-f4e3659b07df"
   },
   "outputs": [],
   "source": [
    "history = []\n",
    "train_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for x, y in loader:\n",
    "#       x=x.view(128, 1, 3, 3)\n",
    "#       print(x.shape)\n",
    "      \n",
    "        \n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      output = model(x)\n",
    "      loss = criterion(output, y)\n",
    "      loss.backward()\n",
    "\n",
    "      train_losses.append(loss.item())        \n",
    "      optimizer.step()\n",
    "    \n",
    "    print(accuracy(model, train), accuracy(model, val))\n",
    "        \n",
    "    plt.plot(train_losses)\n",
    "    plt.show()\n",
    "        # теперь сами:\n",
    "        # 0. распакавать данные на нужное устройство\n",
    "        # 1. сбросить градиент\n",
    "        # 2. прогнать данные через сеть\n",
    "        # 3. посчитать loss\n",
    "        # 4. залоггировать его куда-нибудь\n",
    "        # 5. сделать backward\n",
    "        # 6. optimizer.step()\n",
    "        # (7. вывести пример колоризации -- см код ниже)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBNm1e_qghhy"
   },
   "source": [
    "В подобных нечётко поставленных задачах важно смотреть не цифры, а на реальные примеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ug2GymGvghh1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for t in range(10):\n",
    "    img_gray, img_true = dataset[t]\n",
    "    img_pred = model.predict(X.to(device).unsqueze(0)).detach().cpu().numpy()\n",
    "    #            \"вставь единицу в shape\" ^\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    plt.subplot(141)\n",
    "    plt.axis('off')\n",
    "    plt.set_cmap('Greys')\n",
    "    plt.imshow(img_gray.reshape((80, 108)))\n",
    "\n",
    "    plt.subplot(142)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_pred)\n",
    "\n",
    "    plt.subplot(143)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_true)\n",
    "    \n",
    "    plt.subplot(144)\n",
    "    plt.axis('off')\n",
    "    plt.set_cmap('Reds')\n",
    "    diff = (img_true - img_grey)**2\n",
    "    diff = np.sum(diff, axis=2)\n",
    "    plt.imshow(diff)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9DrW6mD7ghh5"
   },
   "source": [
    "## *Тизер: adversarial loss\n",
    "\n",
    "У нашего подхода к колоризации есть одна весьма существенная проблема: непонятно, как определять функцию потерь. Выясняется, что l1 или l2 в некоторых случаях даже являются принципиально неправильным выбором. Представьте, что у нас есть датасет фотографий с летнего лагеря, в котором все люди ходят в футболках двух разных цветов — например, красного и синего — интенсивность которых одинакова и неотличима на черно-белых версиях. Тогда наш лосс заставит сеть выбирать что-то «по середине» (в случае с l2 это будет среднее, а с l1 медиана), и, скорее всего, она сгенерирует что-то серое, в то время как она должна с какой-то вероятностью сгенерировать явно красную или явно синюю футболку.\n",
    "\n",
    "Решение в следующем: выход (колоризованное изображение) кормить в другую сеть, которая учится определять «правдоподобность» раскраски. Помимо восстановления изображения с точки зрения какой-то меры близости, сети-генератору (колоризатору) нужно ещё и обмануть сеть-дискриминатор, а сети-дискриминатору нужно наоборот, учиться отличать настоящую колоризацию от нашей.\n",
    "\n",
    "Подобные схемы с двумя состязяющимися сетями называют GAN-ам (Generative Adversarial Networks), о которых мы поговорим через занятие."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Convolution networks",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
