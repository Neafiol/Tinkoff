{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae_em.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neafiol/Tinkoff/blob/master/vae_em.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rfitdccJiGLB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Вариационный автоэнкодер\n",
        "\n",
        "Мотивация: нам никто вообще не гарантирует, что автоэнкодер работает, и что у него какое-то адекватное латентное пространство."
      ]
    },
    {
      "metadata": {
        "id": "UP5Ay1BEiGLR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aaNEgDIdiGLb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = datasets.MNIST('mnist', train=True, download=True, transform=transforms.ToTensor())\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qjwlHo-siGLn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, image_channels=1, h_dim=256, z_dim=32):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = nn.Sequential(\n",
        "            # ...\n",
        "        )\n",
        "        \n",
        "        self.h2mu = nn.Linear(h_dim, z_dim)\n",
        "        self.h2sigma = nn.Linear(h_dim, z_dim)\n",
        "        self.z2h = nn.Linear(z_dim, h_dim)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            # ...\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        # если не понимаете, как это работает, спросите\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        eps = torch.randn(*mu.size())\n",
        "        z = mu + std * eps\n",
        "        return z\n",
        "    \n",
        "    def bottleneck(self, h):\n",
        "        mu = self.h2mu(h)\n",
        "        logvar = self.h2sigma(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return z, mu, logvar\n",
        "        \n",
        "    def encode(self, x):\n",
        "        # это можно использовать для морфинга, например\n",
        "        return self.bottleneck(self.encoder(x))[0]\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(self.z2h(z))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        z, mu, logvar = self.bottleneck(h)\n",
        "        z = self.z2h(z)\n",
        "        return self.decoder(z), mu, logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oR7o1FBNiGLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4RSvnbGaiGL0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = VAE()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ObP-T9diGL6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    train_loss = 0\n",
        "    for data, _ in tqdm.tqdm(loader):\n",
        "        # если вам лень писать свёртки:\n",
        "        # data = data.view(-1, 784)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        \n",
        "        loss = vae_loss(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "    print('epoch %d, loss %.4f' % (epoch, train_loss / len(dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RaTwzpHRiGMI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML, display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G9BysauPiGMS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get(x):\n",
        "    return dataset[x][0].view(1, 784)  # измените формат, если хотите использовать свёртки\n",
        "\n",
        "def imshow(img):\n",
        "    pic = img.numpy().astype('float')\n",
        "    plt.axis('off')\n",
        "    return plt.imshow(pic, cmap='Greys', animated=True)\n",
        "\n",
        "def morph(inputs, steps, delay):\n",
        "    latent = [model.encode(get(k)).data for k in inputs]\n",
        "    fig = plt.figure()\n",
        "    images = []\n",
        "    for a, b in zip(latent, latent[1:] + [latent[0]]):\n",
        "        for t in np.linspace(0, 1, steps):\n",
        "            c = a*(1-t)+b*t\n",
        "            morphed = model.decode(c).data\n",
        "            morphed = morphed.view(28, 28)\n",
        "            images.append([imshow(morphed)])\n",
        "    \n",
        "    ani = animation.ArtistAnimation(fig, images, interval=delay)\n",
        "\n",
        "    display(HTML(ani.to_html5_video()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HuEKNP_NiGMi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "morph(np.random.randint(0, len(dataset), 30), 20, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XLVxlAJLiGMt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Дополнительное чтение для ноулайферов: [Tutorial on Variational Autoencoders](https://arxiv.org/pdf/1606.05908.pdf)."
      ]
    },
    {
      "metadata": {
        "id": "yQYsKwbFiGMv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# EM-алгоритм"
      ]
    },
    {
      "metadata": {
        "id": "rTDM2CnliGMx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Это задание было украдено с Deep Bayes 2018, а там оно в свою очередь было украдено у Чешского технического универсистета.\n",
        "\n",
        "Данные скачать можно тут: https://goo.gl/6eD3BB\n",
        "\n",
        "Немного помучайтесь с математикой, а когда надоест, посмотрите выводы формул здесь: https://github.com/bayesgroup/deepbayes-2018/blob/master/day1_em/seminar_em.pdf"
      ]
    },
    {
      "metadata": {
        "id": "M2cfmAG_iGMy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Легенда такая: есть $K$ изображений, на которых изображен один из организаторов DeepBayes, но все из них были повреждены следующим процессом: есть фиксированное черно-белое изображение-фон $B$ (размера $W \\times H$), в каждом изоражении лицо $F$ (размера $w \\times H$) помещается в случайное место на фоне (для каждого изображения выбирается горизонтальный сдвиг $d_k$; априорные вероятности каждого сдвига обучаемы). Помимо этого, ко всем изображениям подмешивается белый шум (независимо ко всем пикселям) со средним 0 и дисперсией $s^2$.\n",
        "\n",
        "Ваша задача — восстановить лицо. Формально, нужно найти такую матрицу, что правдоподобие сгенерированных изображений максимально."
      ]
    },
    {
      "metadata": {
        "id": "obD7dAyiiGM0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Bs4AG3wiGM9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w = 73  # ширина лица\n",
        "X = np.load(\"data_em\")  # путь до данных"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MN-T5TT9iGNE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X[:, :, 0], cmap=\"Greys_r\")\n",
        "plt.axis(\"off\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j45w69vFiGNM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Наша цель — найти лицо $F$ (матрица размера $H \\times w$).\n",
        "\n",
        "Также в процессе нам потребуется найти:\n",
        "* $B$: фон  ($H \\times W$)\n",
        "* $s^2$: дисперсию шума (скаляр)\n",
        "* $a$: априорные вероятности сдвигов ($W-w+1$ штук, должны суммироваться в единицу)\n",
        "* $q(d)$: постериорные вероятности сдвигов для каждого изображения  (($W-w+1$) x $K$)\n",
        "\n",
        "План реализации такой:\n",
        "1. Вычислить $\\log p(X  \\mid d,\\,F,\\,B,\\,s)$\n",
        "2. E-шаг: посчитать $q(d)$\n",
        "3. M-шаг: найти самые правдоподобные $F,\\, B, \\,s, \\,a$\n",
        "4. Соединить вместе E-шаг и M-шаг"
      ]
    },
    {
      "metadata": {
        "id": "GVNUy9VziGNN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EM-алгоритм может работать долго, и на больших данных его трудно тестировать\n",
        "tH, tW, tw, tK = 2, 3, 1, 2\n",
        "tX = np.arange(tH*tW*tK).reshape(tH, tW, tK)\n",
        "tF = np.arange(tH*tw).reshape(tH, tw)\n",
        "tB = np.arange(tH*tW).reshape(tH, tW)\n",
        "ts = 0.1\n",
        "ta = np.arange(1, (tW-tw+1)+1)\n",
        "ta = ta / ta.sum()\n",
        "tq = np.arange(1, (tW-tw+1)*tK+1).reshape(tW-tw+1, tK)\n",
        "tq = tq / tq.sum(axis=0)[np.newaxis, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k68Rdi01iGNS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Вычисляем лог-вероятности\n",
        "\n",
        "Для $k$-го изображения $X_k$ и сдвига $d_k$, его правдоподобие будет равно:\n",
        "\n",
        "$$p(X_k  \\mid d_k,\\,F,\\,B,\\,s) = \\prod_{ij}\n",
        "    \\begin{cases} \n",
        "    \t\\mathcal{N}(X_k[i,j]\\mid F[i,\\,j-d_k],\\,s^2), \n",
        "    \t& \\text{if}\\, (i,j)\\in faceArea(d_k)\\\\\n",
        "    \t\\mathcal{N}(X_k[i,j]\\mid B[i,j],\\,s^2), & \\text{else}\n",
        "    \\end{cases}$$\n",
        "\n",
        "Примечание:\n",
        "* Не забудьте, что нам нужен логарифм всего этого.\n",
        "* Желательно использовать не более одного цикла."
      ]
    },
    {
      "metadata": {
        "id": "sbuCqq7qiGNV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculate_log_probability(X, F, B, s):\n",
        "    \"\"\"\n",
        "    Calculates log p(X_k|d_k, F, B, s) for all images X_k in X and\n",
        "    all possible face position d_k.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape (H, W, K)\n",
        "        K images of size H x W.\n",
        "    F : array, shape (H, w)\n",
        "        Estimate of prankster's face.\n",
        "    B : array, shape (H, W)\n",
        "        Estimate of background.\n",
        "    s : float\n",
        "        Estimate of standard deviation of Gaussian noise.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ll : array, shape(W-w+1, K)\n",
        "        ll[dw, k] - log-likelihood of observing image X_k given\n",
        "        that the prankster's face F is located at position dw\n",
        "    \"\"\"\n",
        "    # your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q7pDpIF9iGNi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run this cell to test your implementation\n",
        "expected = np.array([[-3541.69812064, -5541.69812064],\n",
        "       [-4541.69812064, -6741.69812064],\n",
        "       [-6141.69812064, -8541.69812064]])\n",
        "actual = calculate_log_probability(tX, tF, tB, ts)\n",
        "assert np.allclose(actual, expected)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gn0KP8MNiGNo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## `сalculate_lower_bound`\n",
        "\n",
        "$$\\mathcal{L}(q, \\,F, \\,B,\\, s,\\, a) = \\sum_k \\biggl (\\mathbb{E} _ {q( d_k)}\\bigl ( \\log p(  X_{k}  \\mid {d}_{k} , \\,F,\\,B,\\,s) + \n",
        "    \\log p( d_k  \\mid a)\\bigr) - \\mathbb{E} _ {q( d_k)} \\log q( d_k)\\biggr) $$\n",
        "    \n",
        "Примечания:\n",
        "* Вы уже реализовали `calculate_log_probability` — используйте её. \n",
        "* Распределения $q(d_k)$ и $p( d_k  \\mid a)$ дискретные. For example, $P(d_k=i \\mid a) = a[i]$.\n",
        "* Старайтесь не использовать циклы."
      ]
    },
    {
      "metadata": {
        "id": "_p3xtDB8iGNr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculate_lower_bound(X, F, B, s, a, q):\n",
        "    \"\"\"\n",
        "    Calculates the lower bound L(q, F, B, s, a) for \n",
        "    the marginal log likelihood.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape (H, W, K)\n",
        "        K images of size H x W.\n",
        "    F : array, shape (H, w)\n",
        "        Estimate of prankster's face.\n",
        "    B : array, shape (H, W)\n",
        "        Estimate of background.\n",
        "    s : float\n",
        "        Estimate of standard deviation of Gaussian noise.\n",
        "    a : array, shape (W-w+1)\n",
        "        Estimate of prior on position of face in any image.\n",
        "    q : array\n",
        "        q[dw, k] - estimate of posterior \n",
        "                   of position dw\n",
        "                   of prankster's face given image Xk\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    L : float\n",
        "        The lower bound L(q, F, B, s, a) \n",
        "        for the marginal log likelihood.\n",
        "    \"\"\"\n",
        "    # your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S8Q-xcLLiGNx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "expected = -12761.1875\n",
        "actual = calculate_lower_bound(tX, tF, tB, ts, ta, tq)\n",
        "assert np.allclose(actual, expected)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xT0MMu1GiGN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## E-step\n",
        "\n",
        "$$q(d_k) = p(d_k \\mid X_k, \\,F, \\,B, \\,s,\\, a) = \n",
        "\\frac {p(  X_{k}  \\mid {d}_{k} , \\,F,\\,B,\\,s)\\, p(d_k \\mid a)}\n",
        "{\\sum_{d'_k} p(  X_{k}  \\mid d'_k , \\,F,\\,B,\\,s) \\,p(d'_k \\mid a)}$$\n",
        "\n",
        "Примечания:\n",
        "* Используйте `calculate_log_probability`.\n",
        "* Ради вычислительной стабильности, используйте операции с логарифмированными значениями и только в конце возводите в экспоненту. Также используйте этот трюк с софтмаксом:\n",
        "$$\\beta_i = \\log{p_i(\\dots)} \\quad\\rightarrow \\quad\n",
        "\t\\frac{e^{\\beta_i}}{\\sum_k e^{\\beta_k}} = \n",
        "\t\\frac{e^{(\\beta_i - \\max_j \\beta_j)}}{\\sum_k e^{(\\beta_k- \\max_j \\beta_j)}}$$\n",
        "* Старайтесь не использовать циклы"
      ]
    },
    {
      "metadata": {
        "id": "lHgUm_C6iGOC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_e_step(X, F, B, s, a):\n",
        "    \"\"\"\n",
        "    Given the current esitmate of the parameters, for each image Xk\n",
        "    esitmates the probability p(d_k|X_k, F, B, s, a).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape(H, W, K)\n",
        "        K images of size H x W.\n",
        "    F  : array_like, shape(H, w)\n",
        "        Estimate of prankster's face.\n",
        "    B : array shape(H, W)\n",
        "        Estimate of background.\n",
        "    s : float\n",
        "        Eestimate of standard deviation of Gaussian noise.\n",
        "    a : array, shape(W-w+1)\n",
        "        Estimate of prior on face position in any image.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    q : array\n",
        "        shape (W-w+1, K)\n",
        "        q[dw, k] - estimate of posterior of position dw\n",
        "        of prankster's face given image Xk\n",
        "    \"\"\"\n",
        "    # your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSPtccPViGOI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "expected = np.array([[ 1.,  1.],\n",
        "                   [ 0.,  0.],\n",
        "                   [ 0.,  0.]])\n",
        "actual = run_e_step(tX, tF, tB, ts, ta)\n",
        "assert np.allclose(actual, expected)\n",
        "print(\"OK\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-H47Ki2CiGOQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## M-step\n",
        "\n",
        "$$a[j] = \\frac{\\sum_k q( d_k = j )}{\\sum_{j'}  \\sum_{k'} q( d_{k'} = j')}$$\n",
        "$$F[i, m] = \\frac 1 K  \\sum_k \\sum_{d_k} q(d_k)\\, X^k[i,\\, m+d_k]$$\n",
        "$$B[i, j] = \\frac {\\sum_k \\sum_{ d_k:\\, (i, \\,j) \\,\\not\\in faceArea(d_k)} q(d_k)\\, X^k[i, j]} \n",
        "\t  \t{\\sum_k \\sum_{d_k: \\,(i, \\,j)\\, \\not\\in faceArea(d_k)} q(d_k)}$$\n",
        "$$s^2 = \\frac 1 {HWK}   \\sum_k \\sum_{d_k} q(d_k)\n",
        "\t  \t\\sum_{i,\\, j}  (X^k[i, \\,j] - M^{d_k}[i, \\,j])^2$$\n",
        "\n",
        "где $M^{d_k}[i, j]$ это изображение из фона, с наложенным на него лицом со сдвигом $d_k$.\n",
        "\n",
        "Примечания:\n",
        "* Порядок обновления параметров: $a$, $F$, $B$, $s$.\n",
        "* Когда параметр обновляется, его __новое__ значение используется для обновления других параметров.\n",
        "* Используйте не более 3 циклов (отдельных, не вложенных)."
      ]
    },
    {
      "metadata": {
        "id": "_XjcpH_NiGOT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_m_step(X, q, w):\n",
        "    \"\"\"\n",
        "    Estimates F, B, s, a given esitmate of posteriors defined by q.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape (H, W, K)\n",
        "        K images of size H x W.\n",
        "    q  :\n",
        "        q[dw, k] - estimate of posterior of position dw\n",
        "                   of prankster's face given image Xk\n",
        "    w : int\n",
        "        Face mask width.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    F : array, shape (H, w)\n",
        "        Estimate of prankster's face.\n",
        "    B : array, shape (H, W)\n",
        "        Estimate of background.\n",
        "    s : float\n",
        "        Estimate of standard deviation of Gaussian noise.\n",
        "    a : array, shape (W-w+1)\n",
        "        Estimate of prior on position of face in any image.\n",
        "    \"\"\"\n",
        "    # your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hBOphEhoiGOX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "expected = [\n",
        "    np.array([[ 3.27777778],\n",
        "              [ 9.27777778]]),\n",
        "    np.array([[  0.48387097, 2.5       ,   4.52941176],\n",
        "              [  6.48387097, 8.5       ,  10.52941176]]),\n",
        "    0.94868,\n",
        "    np.array([ 0.13888889,  0.33333333,  0.52777778])\n",
        "]\n",
        "actual = run_m_step(tX, tq, tw)\n",
        "for a, e in zip(actual, expected):\n",
        "    assert np.allclose(a, e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4n20_gGziGOi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Соединяем всё вместе\n",
        "\n",
        "Инициализируйте чем-нибудь параметры, и повторяйте E- и M-шаги до сходимости. $\\mathcal{L}(q, \\,F, \\,B, \\,s, \\,a)$ должна строго увеличиваться после каждой итерации."
      ]
    },
    {
      "metadata": {
        "id": "alCl9O6uiGOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_EM(X, w, F=None, B=None, s=None, a=None, tolerance=0.001, max_iter=50):\n",
        "    \"\"\"\n",
        "    Runs EM loop until the likelihood of observing X given current\n",
        "    estimate of parameters is idempotent as defined by a fixed\n",
        "    tolerance.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape (H, W, K)\n",
        "        K images of size H x W.\n",
        "    w : int\n",
        "        Face mask width.\n",
        "    F : array, shape (H, w), optional\n",
        "        Initial estimate of prankster's face.\n",
        "    B : array, shape (H, W), optional\n",
        "        Initial estimate of background.\n",
        "    s : float, optional\n",
        "        Initial estimate of standard deviation of Gaussian noise.\n",
        "    a : array, shape (W-w+1), optional\n",
        "        Initial estimate of prior on position of face in any image.\n",
        "    tolerance : float, optional\n",
        "        Parameter for stopping criterion.\n",
        "    max_iter  : int, optional\n",
        "        Maximum number of iterations.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    F, B, s, a : trained parameters.\n",
        "    LL : array, shape(number_of_iters + 2,)\n",
        "        L(q, F, B, s, a) at initial guess, \n",
        "        after each EM iteration and after\n",
        "        final estimate of posteriors;\n",
        "        number_of_iters is actual number of iterations that was done.\n",
        "    \"\"\"\n",
        "    H, W, N = X.shape\n",
        "    if F is None:\n",
        "        F = np.random.randint(0, 255, (H, w))\n",
        "    if B is None:\n",
        "        B = np.random.randint(0, 255, (H, W))\n",
        "    if a is None:\n",
        "        a = np.ones(W - w + 1)\n",
        "        a /= np.sum(a)\n",
        "    if s is None:\n",
        "        s = np.random.rand()*pow(64,2)\n",
        "    # your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cka1nh3XiGOt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "res = run_EM(tX, tw, max_iter=3)\n",
        "LL = res[-1]\n",
        "assert np.alltrue(LL[1:] - LL[:-1] > 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PpTlfVN9iGOz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Так кто же на фотке?"
      ]
    },
    {
      "metadata": {
        "id": "UIVUDdIwiGO0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show(F, i=1, n=1):\n",
        "    plt.subplot(1, n, i)\n",
        "    plt.imshow(F, cmap=\"Greys_r\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bph9YJxuiGO6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "F, B, s, a = [None] * 4\n",
        "LL = []\n",
        "lens = [50, 100, 300, 500, 1000]\n",
        "iters = [5, 1, 1, 1, 1]\n",
        "plt.figure(figsize=(20, 5))\n",
        "for i, (l, it) in enumerate(zip(lens, iters)):\n",
        "    F, B, s, a, _ = run_EM(X[:, :, :l], w, F, B, s, a, max_iter=it)\n",
        "    show(F, i+1, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}