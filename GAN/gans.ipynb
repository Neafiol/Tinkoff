{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8coLQ3KOu4cA"
   },
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "Применение adversarial loss (более общей идеи, лежащей в основе GANов) позволило решить задачи, которые казались невозможными:\n",
    "\n",
    "* [Машинный перевод без параллельных данных](https://arxiv.org/pdf/1710.11041.pdf)\n",
    "* [Циклоганы: перевод изображений в другой домен](https://arxiv.org/abs/1703.10593)\n",
    "* Колоризация и [Super Resolution](https://arxiv.org/abs/1807.02758)\n",
    "* [Генерация и морфинг произвольных данных](https://arxiv.org/pdf/1809.11096.pdf) ([тут](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb#scrollTo=HuCO9tv3IKT2) можно поиграться с генерацией бургеров)\n",
    "* Применения в борьбе с adversarial атаками\n",
    "\n",
    "Вот постоянно пополняющийся список приложений GANов: https://github.com/nashory/gans-awesome-applications\n",
    "\n",
    "Сама [статья](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf) Яна Гудфеллоу про GANы вышла в конце 2014 года и была процитирована 7687 раз за 4 года.\n",
    "\n",
    "\n",
    "<img width='500px' src='https://cdn-images-1.medium.com/max/800/1*eWURQXT41pwHvDg1xDiEmw.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZdtbv7Qu4cE"
   },
   "source": [
    "Теперь немного формальных определений:\n",
    "\n",
    "* Пусть $z$ — это вектор из латентного пространства, насэмпленный из нормального распределения.\n",
    "* $G(z)$ обозначает функцию генератора, которая отображает латентный вектор в пространство данных. Цель $G$ — оценить истинное распределение данных $p_d$, чтобы сэмплировать данные из оцененного распределения $p_g$.\n",
    "* $D(G(z))$ это вероятность (число от 0 до 1), что выход генератора $G$ является реальным изображением.\n",
    "\n",
    "$D$ и $G$ играют в минимаксную игру, в которой $D$ старается максимизировать вероятность, что он правильно классифицирует реальные и сгенерированные сэмплы, а $G$ старается минимизировать эту вероятность:\n",
    "\n",
    "$$\\underset{G}{\\text{min}} \\underset{D}{\\text{max}}V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)}\\big[logD(x)\\big] + \\mathbb{E}_{z\\sim p_{z}(z)}\\big[log(1-D(G(x)))\\big]$$\n",
    "\n",
    "[Выясняется](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), что решение в этой минимаксной игре достигается при $p_g = p_d$ (и дискриминатор в этом случае может угадывать случайно). В реальности модели не всегда могут сойтись к этой точке.\n",
    "\n",
    "[DCGAN](https://arxiv.org/pdf/1511.06434.pdf) (Deep Convolutional GAN) называют GAN, который явно использует свёртки и транспонированные свёртки в дискриминаторе и генераторе соответственно. Откройте статью -- мы будем идти очень близко с авторами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYPV9p90wSgG"
   },
   "source": [
    "## Датасет\n",
    "Всем надоели цифры, поэтому обучаться мы будем на датасете CelebA ([Large-scale CelebFaces Attributes](Large-scale CelebFaces Attributes)). В датасете на каждую фотку есть её аттрибуты, но мы их пока использовать не будем.\n",
    "\n",
    "<img width='500px' src='http://mmlab.ie.cuhk.edu.hk/projects/celeba/overview.png'>\n",
    "\n",
    "Автор, когда готовил эту тетрадку, долго думал, как загрузить датасет, чтобы всем было удобно. Это оказалось трудно, потому что прямых ссылок на него нигде нет, и, соответственно, просто сделать `!wget ...` нельзя. По удачному стечению обстоятельств, неделю назад кто-то [добавил](https://github.com/pytorch/vision/blob/master/torchvision/datasets/celeba.py) скрипты для загрузки этого датасета в сам `torchvision`, но в `pip` новая версия за такой срок ещё не успела появиться, поэтому мы обновимся напрямую из репозитория на гитхабе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "roFGEo3b37Wa",
    "outputId": "0cae07b9-23e9-4249-9304-dde5478b82af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/pytorch/vision.git\n",
      "  Cloning https://github.com/pytorch/vision.git to /tmp/pip-req-build-d78bb8nn\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.3) (1.14.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.3) (1.11.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.3) (1.0.1.post2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.3) (4.1.1)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.2.3) (0.46)\n",
      "Building wheels for collected packages: torchvision\n",
      "  Building wheel for torchvision (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-ohnc5_d1/wheels/04/6d/bf/cc14a58bae32d07d1c7d23833dc5ea655e477ff25061b8cd57\n",
      "Successfully built torchvision\n",
      "\u001b[31mfastai 1.0.48 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torchvision\n",
      "  Found existing installation: torchvision 0.2.2.post3\n",
      "    Uninstalling torchvision-0.2.2.post3:\n",
      "      Successfully uninstalled torchvision-0.2.2.post3\n",
      "Successfully installed torchvision-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/pytorch/vision.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7AF9qQ04b2k"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "raBYoUEjeXRm"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')  # не забудьте включить GPU\n",
    "\n",
    "image_size = 64\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "__rYnOod4ded",
    "outputId": "0868e430-d67a-478b-d6ad-3a1a694733a1"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.datasets' has no attribute 'CelebA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0170dc818e9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m ])\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCelebA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torchvision.datasets' has no attribute 'CelebA'"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    # Normalize здесь приводит значения в промежуток [-1, 1]\n",
    "])\n",
    "\n",
    "dataset = datasets.CelebA('data', download=True, transform=transform)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "BE8y2oIB_2N3",
    "outputId": "ddf3c419-8146-40a6-88be-1e7826aee0a0"
   },
   "outputs": [],
   "source": [
    "dataset[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLSFZAaNe9NA"
   },
   "outputs": [],
   "source": [
    "# посмотрите на данные (вы писали нужный код в колоризации)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hv2Jga9EPaeT"
   },
   "source": [
    "## Модель\n",
    "\n",
    "Генератор $G$ преобразует латентный вектор $z$ в пространство данных (в нашем случае -- картинки 3x64x64). В статье используют последовательность блоков из транспонированных свёрток, BatchNorm-ов и ReLU. На выходе каждое значение лежит в [-1, 1] (мы делаем TanH), в соответствии с нормализацией, которую мы сделали раньше.\n",
    "\n",
    "<img width='600px' src='https://pytorch.org/tutorials/_images/dcgan_generator.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xUkaAeWKAYpX"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3CuKv_Zi54ra"
   },
   "outputs": [],
   "source": [
    "num_channels = 3\n",
    "latent_size = 100\n",
    "base_size = 64\n",
    "\n",
    "G = nn.Sequential(\n",
    "    # input is Z, going into a convolution\n",
    "    nn.ConvTranspose2d(latent_size, base_size * 8, 4, 1, 0, bias=False),\n",
    "    nn.BatchNorm2d(base_size * 8),\n",
    "    nn.ReLU(True),\n",
    "    \n",
    "    # (base_size*8) x 4 x 4\n",
    "    nn.ConvTranspose2d(base_size * 8, base_size * 4, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(base_size * 4),\n",
    "    nn.ReLU(True),\n",
    "    \n",
    "    # (base_size*4) x 8 x 8\n",
    "    nn.ConvTranspose2d(base_size * 4, base_size * 2, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(base_size * 2),\n",
    "    nn.ReLU(True),\n",
    "    \n",
    "    # (base_size*2) x 16 x 16\n",
    "    nn.ConvTranspose2d(base_size * 2, base_size, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(base_size),\n",
    "    nn.ReLU(True),\n",
    "    \n",
    "    # (base_size) x 32 x 32\n",
    "    nn.ConvTranspose2d(base_size, num_channels, 4, 2, 1, bias=False),\n",
    "    nn.Tanh()\n",
    "    # (num_channels) x 64 x 64\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "wtv1uteaAcjZ",
    "outputId": "955e54ba-33e4-4203-9f56-bad3ed337edb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0430, -0.1921, -0.0838,  ..., -0.0961,  0.0013, -0.0193],\n",
       "          [-0.0952, -0.2367, -0.3027,  ...,  0.0537, -0.0057, -0.1617],\n",
       "          [ 0.0071, -0.1059, -0.1645,  ..., -0.0812, -0.2847, -0.1735],\n",
       "          ...,\n",
       "          [-0.0262, -0.0089, -0.1760,  ..., -0.1663, -0.2924, -0.1015],\n",
       "          [ 0.0520, -0.0849,  0.0632,  ..., -0.0493, -0.0067, -0.2049],\n",
       "          [ 0.0066, -0.0965, -0.2745,  ..., -0.0040, -0.1068, -0.1311]],\n",
       "\n",
       "         [[-0.2534,  0.1518, -0.3848,  ...,  0.0874, -0.3271, -0.0220],\n",
       "          [-0.0451,  0.1393,  0.2194,  ..., -0.0423, -0.0577,  0.0611],\n",
       "          [-0.1836,  0.0687, -0.2834,  ...,  0.1847, -0.4244,  0.0374],\n",
       "          ...,\n",
       "          [-0.0741, -0.0388,  0.1716,  ..., -0.1594,  0.0327, -0.0295],\n",
       "          [-0.2991,  0.2001, -0.4033,  ...,  0.0508, -0.3711, -0.0573],\n",
       "          [-0.0035,  0.1809,  0.0290,  ...,  0.0626,  0.0673,  0.0036]],\n",
       "\n",
       "         [[ 0.0896, -0.0668, -0.0163,  ..., -0.0538, -0.0037, -0.0130],\n",
       "          [ 0.1059,  0.0368,  0.0493,  ..., -0.1906,  0.1987,  0.0908],\n",
       "          [ 0.2025,  0.2266,  0.0990,  ..., -0.0900,  0.1546, -0.0022],\n",
       "          ...,\n",
       "          [ 0.0080, -0.2323,  0.0183,  ..., -0.0901, -0.0202,  0.0462],\n",
       "          [ 0.0048,  0.0573,  0.1031,  ...,  0.0512,  0.0312, -0.0316],\n",
       "          [-0.1085,  0.1073, -0.1138,  ...,  0.0596, -0.0900,  0.1265]]]],\n",
       "       grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randn(1, latent_size, 1, 1)\n",
    "G(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0c7SaZsidzx"
   },
   "source": [
    "Дискриминатор -- это обычный бинарный классификатор. В статье он устроен симметрично генератору: Conv2d, BatchNorm, ReLU, Conv2d..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZdLcZzviZlD"
   },
   "outputs": [],
   "source": [
    "D = nn.Sequential(\n",
    "\n",
    "    nn.Conv2d(num_channels, base_size , 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(base_size),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    \n",
    "    nn.Conv2d(base_size, base_size * 2, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(base_size * 2),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # state size. (ndf*2) x 16 x 16\n",
    "    nn.Conv2d(base_size * 2, base_size * 4, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(base_size * 4),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # state size. (ndf*4) x 8 x 8\n",
    "    nn.Conv2d(base_size * 4, base_size * 8, 4, 2, 1, bias=False),\n",
    "    nn.BatchNorm2d(base_size * 8),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # state size. (ndf*8) x 4 x 4\n",
    "    nn.Conv2d(base_size * 8, 1, 4, 1, 0, bias=False),\n",
    "    nn.Sigmoid()\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "RF905ABD9cTG",
    "outputId": "b1ac8e53-eb97-45b8-865e-f5f40559c0fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4384]]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randn(1, latent_size, 1, 1).to(device)\n",
    "D(G(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_cvC_RdKiMmS"
   },
   "source": [
    "В статье акцентируют внимание на необходимость нестандартной инициализации весов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTR8nHzu77kZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (9): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  (13): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "# apply рекурсивно применяет применяет функцию ко всем своим подмодулям\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1NV6gwpojEv4"
   },
   "source": [
    "## Обучение\n",
    "\n",
    "У GANов, помимо сходимости, есть проблема, что их непонятно, как сравнивать между собой, потому что у нас не один лосс, а два. Поэтому полезнее во время обучения смотреть на генерируемые картинки, а не цифры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(opt.batchSize, nz, 1, 1, device=device)#для оценки качества\n",
    "\n",
    "num_epochs = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "optimizerD = optim.Adam(D.parameters(), lr=learning_rate)\n",
    "optimizerG = optim.Adam(G.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "i=0\n",
    "for epoch in range(num_epochs):\n",
    "    for (data, _) in loader:\n",
    "        i+=1\n",
    "\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "\n",
    "        # train with real\n",
    "        D.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        \n",
    "        label = torch.full((batch_size,), 1, device=device)\n",
    "\n",
    "        output = D(real_cpu)\n",
    "        D_loss1 = criterion(output, label)\n",
    "        D_loss1.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        z = torch.randn(1, latent_size, 1, 1)\n",
    "        fake_photo = G(z)\n",
    "        label.fill_(0)\n",
    "        output = D(fake.detach())\n",
    "        D_loss2 = criterion(output, label)\n",
    "        D_loss2.backward()\n",
    "\n",
    "        D_loss = D_loss1 + D_loss2\n",
    "        optimizerD.step()\n",
    "\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "\n",
    "        G.zero_grad()\n",
    "        label.fill_(1)  # fake labels are real for generator cost\n",
    "        output = D(fake_photo)\n",
    "        G_loss = criterion(output, label)\n",
    "        G_loss.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        if iters % 10 == 0:\n",
    "            # Выведем информацию о том, как наша сеть справляется\n",
    "            print(f'{epoch}/{num_epochs}, {iters/len(loader)}')\n",
    "            print(f'  G loss: {G_loss}')\n",
    "            print(f'  D loss: {D_loss}')\n",
    "            print()\n",
    "            \n",
    "        if i % 50 == 0:\n",
    "            fake = G(fixed_noise)\n",
    "            img_list.append(fake)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHXRu3cN8--y"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "optim_G = # ваш любимый оптимизатор параметров дискриминатора\n",
    "optim_D = # ваш любимый оптимизатор параметров генератора\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for (data, _) in loader:\n",
    "        # Обучать GANы всегда долго, и мы хотим по максимуму переиспользовать вычисления\n",
    "\n",
    "        # 1. Обучим D: max log(D(x)) + log(1 - D(G(z)))\n",
    "        \n",
    "        D.zero_grad()\n",
    "        \n",
    "        # a) Распакуйте данные на нужный девайс\n",
    "        #    Прогоните через сеть\n",
    "        #    Сгенерируйте вектор из единичек (ответы для реальных сэмплов)\n",
    "        #    Посчитайте лосс, сделайте .backward()\n",
    "        # b) Посэмплите из torch.randn\n",
    "        #    Прогоните этот шум через генератор\n",
    "        #    detach-ните (нам не нужно считать градиенты G)\n",
    "        #    Прогоните через дискриминатор\n",
    "        #    Сгенерите вектор из нулей (ответы для фейков)\n",
    "        #    Посчитайте лосс, сделайте backward (он сложится, а не перезапишется)\n",
    "        #\n",
    "        #    Также можно сначала сгенерировать данные, а потом собрать из двух частей батч,\n",
    "        #    В котором первая половина лэйблов будет нулями, а вторая -- единицами\n",
    "        \n",
    "        optim_D.step()\n",
    "        \n",
    "\n",
    "        # 2. Обучим G: max log(D(G(z)))\n",
    "\n",
    "        G.zero_grad()\n",
    "        \n",
    "        # Тут проще:\n",
    "        #    Получим вектор неправильных ответов -- вектор единиц (мы ведь хотим, чтобы D считал их неправильными)\n",
    "        #    Прогоним ранее сгенерированные картинки через D\n",
    "        #    Посчитаем лосc, сделаем .backward()\n",
    "        \n",
    "        optim_G.step()\n",
    "\n",
    "        # Раз в сколько-то итераций логгируем лосс\n",
    "        if iters % 10 == 0:\n",
    "            # Выведем информацию о том, как наша сеть справляется\n",
    "            print(f'{epoch}/{num_epochs}, {iters/len(loader)}')\n",
    "            print(f'  G loss: {G_loss}')\n",
    "            print(f'  D loss: {D_loss}')\n",
    "            print()\n",
    "            \n",
    "        D_losses.append(D_loss.item())\n",
    "        G_losses.append(G_loss.item())\n",
    "\n",
    "        if iters % 50 == 0:\n",
    "            # вы на этом батче уже генерировали какие-то картинки: просто добавьте их в список\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53H3JFfJveS2"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(G_losses, label=\"G\")\n",
    "plt.plot(D_losses, label=\"D\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jP4hziIekgfg"
   },
   "outputs": [],
   "source": [
    "# распечатайте ваши картинки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kUdCbvsZgXq"
   },
   "source": [
    "### Что дальше?\n",
    "\n",
    "Довольно старый, но актуальный список трюков: https://github.com/soumith/ganhacks\n",
    "\n",
    "Вообще, теория сходимости GANов очень сильно развилась за последнее время. Если хотите во всём этом разобраться, то возьмите какую-нибудь [достаточно новую статью](https://arxiv.org/pdf/1802.05957.pdf) и рекурсивно почитайте оттуда абстракты из списока литературы."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gans.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
