{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rnn_sentiment_dz.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neafiol/Tinkoff/blob/master/Rnn/Rnn_sentiment_dz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6aMrbyco0EWT",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tn-HHdDC0EXz"
      },
      "source": [
        "# Сентимент анализ \n",
        "\n",
        "пишем сами с нуля\n",
        "\n",
        "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment1.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2OE9H_eM0EX1",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nZOHVoNH0EX4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ba7a9bf7-7aef-416a-ba25-5e423ff6ee3e"
      },
      "source": [
        "from torchtext import datasets\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL, root=\"./data\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 48.1MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Heo6yauU0EX_",
        "outputId": "935f5e28-fddb-4dfa-923a-d56b196c3f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')\n",
        "\n",
        "print(vars(train_data.examples[0])['text'])\n",
        "len(train_data.examples)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n",
            "['I', 'saw', 'Heartland', 'when', 'it', 'was', 'first', 'released', 'in', '1980', 'and', 'I', 'have', 'just', 'seen', 'it', 'again', '.', 'It', 'improves', 'with', 'age', '.', 'Heartland', 'is', 'not', 'just', 'for', 'lovers', 'of', '\"', 'indie', '\"', 'films', '.', 'At', 'a', 'time', 'when', 'most', 'American', 'films', 'are', 'little', 'more', 'than', 'cynical', 'attempts', 'to', 'make', 'money', 'with', 'CGI', ',', 'pyrotechnics', ',', 'and/or', 'vulgarity', ',', 'Heartland', 'holds', 'up', 'as', 'a', 'slice', 'of', 'American', 'history', '.', 'It', 'is', 'also', 'a', 'reminder', 'of', 'how', 'spoiled', 'most', 'of', 'us', 'modern', ',', 'urbanized', 'Americans', 'are.<br', '/><br', '/>Nothing', 'in', 'this', 'film', 'is', 'overstated', 'or', 'stagey', '.', 'No', 'one', 'declaims', 'any', 'Hollywood', 'movie', 'speeches', '.', 'The', 'actors', 'really', 'inhabit', 'their', 'roles', '.', 'This', 'really', 'feels', 'like', 'a', '\"', 'small', '\"', 'film', 'but', 'really', 'it', 'is', 'bigger', 'than', 'most', 'multizillion', '-', 'dollar', 'Hollywood', 'productions.<br', '/><br', '/>The', 'film', 'is', 'based', 'on', 'the', 'lives', 'of', 'real', 'people', '.', 'In', '1910', ',', 'Elinore', 'Randall', '(', 'Conchata', 'Ferrell', ',', 'who', 'has', 'never', 'done', 'anything', 'better', 'than', 'this', ')', ',', 'a', 'widow', 'with', 'a', '7-year', '-', 'old', 'daughter', 'Jerrine', '(', 'Megan', 'Folsom', ')', ',', 'is', 'living', 'in', 'Denver', 'but', 'wants', 'more', 'opportunities', '.', 'She', 'advertises', 'for', 'a', 'position', 'as', 'housekeeper', '.', 'The', 'ad', 'is', 'answered', 'by', 'Clyde', 'Stewart', '(', 'Rip', 'Torn', ',', 'one', 'of', 'our', 'most', 'under', '-', 'appreciated', 'actors', ')', ',', 'a', 'Scots', '-', 'born', 'rancher', ',', 'himself', 'a', 'widower', ',', 'with', 'a', 'homestead', 'outside', 'of', 'Burnt', 'Fork', ',', 'Wyoming', '.', 'Elinore', 'accepts', 'the', 'position', '(', 'seven', 'dollars', 'a', 'week', '!', ')', 'and', 'moves', 'up', 'to', 'Wyoming', 'with', 'her', 'daughter', '.', 'She', 'and', 'her', 'daughter', 'move', 'into', 'Stewart', \"'s\", 'tiny', 'house', 'on', 'the', 'property', '.', 'It', 'is', 'rolling', ',', 'treeless', 'rangeland', ',', 'a', 'place', 'of', 'endless', 'vistas', 'where', 'the', 'silence', 'is', 'broken', 'only', 'by', 'the', 'sounds', 'made', 'by', 'these', 'people', 'and', 'their', 'animals', '.', 'It', \"'s\", 'guaranteed', 'to', 'make', 'a', 'person', 'feel', 'small', '.', 'The', 'three', 'characters', 'go', 'for', 'long', 'periods', 'without', 'seeing', 'another', 'human', 'soul', '.', 'What', 'is', 'worse', ',', 'Stewart', 'turns', 'out', 'to', 'be', 'taciturn', 'to', 'the', 'point', 'of', 'being', 'almost', 'silent', '.', '\"', 'I', 'ca', \"n't\", 'talk', 'to', 'the', 'man', ',', '\"', 'Elinore', 'complains', 'to', 'Grandma', 'Landauer', '.', '\"', 'You', \"'d\", 'better', 'learn', 'before', 'winter', ',', '\"', 'replies', 'Grandma', '.', 'Grandma', '(', 'Lilia', 'Skala', ')', 'is', 'one', 'of', 'the', 'only', 'two', 'other', 'characters', 'who', 'are', 'seen', 'more', 'than', 'fleetingly', '.', 'She', 'came', 'out', 'to', 'Wyoming', 'from', 'Germany', 'with', 'her', 'husband', 'many', 'years', 'before', 'and', 'runs', 'her', 'ranch', 'alone', 'now', 'that', 'she', 'is', 'also', 'widowed', '.', 'Grandma', 'is', 'their', 'nearest', 'neighbor', '(', 'and', 'the', 'local', 'midwife', ')', 'and', 'still', 'she', 'lives', 'ten', 'miles', 'away', '!', 'The', 'other', 'supporting', 'character', 'is', 'Jack', 'the', 'hired', 'hand', '(', 'Barry', 'Primus).<br', '/><br', '/>Elinore', \"'s\", 'routine', '(', 'and', 'her', 'employer', \"'s\", ')', 'is', 'one', 'of', 'endless', ',', 'backbreaking', 'labor', ',', 'where', 'there', 'are', 'no', 'modern', 'conveniences', 'and', 'where', 'everything', 'must', 'be', 'made', ',', 'fixed', 'or', 'done', 'by', 'hand', '.', 'This', 'is', 'the', 'real', 'meat', 'of', 'the', 'film', ':', 'Watching', 'the', 'ordinary', 'life', 'of', 'these', 'ranchers', 'as', 'they', 'struggle', 'against', 'nature', 'to', 'wrest', 'a', 'living', 'from', 'the', 'land', '.', 'But', 'despite', 'the', 'constant', 'toil', 'and', 'fatigue', ',', 'Elinore', 'is', 'always', 'looking', 'for', 'other', 'opportunities', '.', 'She', 'learns', 'that', 'the', 'tract', 'adjacent', 'to', 'Stewart', \"'s\", 'is', 'unclaimed', '.', 'Impulsively', ',', 'she', 'files', 'a', 'claim', 'on', 'the', 'property', '(', 'twelve', 'dollars', ',', 'or', 'almost', 'two', 'weeks', \"'\", 'pay', '!', ')', ',', 'meaning', 'that', 'if', 'she', 'lives', 'on', 'it', '(', 'and', 'she', 'must', 'actually', 'live', 'there', ')', 'and', 'works', 'it', 'for', 'ten', 'years', ',', 'she', 'will', 'get', 'the', 'deed', 'to', 'it', '.', 'Naturally', ',', 'Stewart', 'learns', 'what', 'she', 'has', 'done', '.', 'With', 'merciless', 'logic', ',', 'he', 'points', 'out', 'that', 'with', 'no', 'money', ',', 'no', 'livestock', ',', 'no', 'credit', ',', 'and', 'no', 'assets', ',', 'she', 'has', 'no', 'chance', 'of', 'succeeding', '.', 'He', 'then', 'offers', 'a', 'solution', ':', 'He', 'proposes', 'marriage', '.', 'The', 'stunned', 'Elinore', 'realizes', 'that', 'this', 'is', 'the', 'only', 'real', 'alternative', ',', 'and', 'accepts.<br', '/><br', '/>We', 'think', 'that', 'Stewart', \"'s\", 'proposal', 'is', 'purely', 'Machiavellian', '---', 'he', 'wants', 'the', 'land', 'and', 'the', 'free', 'labor', '---', 'but', 'we', 'see', 'that', ',', 'in', 'fact', ',', 'he', 'is', 'genuinely', 'fond', 'of', 'Elinore', ',', 'and', 'they', 'grow', 'together', 'as', 'a', 'couple', '.', 'She', 'becomes', 'pregnant', ';', 'she', 'goes', 'into', 'labor', 'in', 'the', 'middle', 'of', 'a', 'midwinter', 'blizzard', ';', 'Clyde', 'travels', 'for', 'hours', 'on', 'horseback', 'through', 'the', 'storm', 'the', 'ten', 'miles', 'to', 'Grandma', \"'s\", 'and', 'the', 'ten', 'miles', 'back', ',', 'only', 'to', 'announce', 'that', 'Grandma', 'was', \"n't\", 'there', '.', 'This', 'is', 'more', 'like', 'real', 'life', 'than', 'is', 'pleasant', ',', 'folks', '.', 'Elinore', 'has', 'the', 'baby', 'all', 'by', 'herself', ',', 'with', 'no', 'help', 'whatsoever', '.', 'Their', 'son', 'is', 'still', 'an', 'infant', 'when', 'he', 'gets', 'sick', 'and', 'dies', '.', 'They', 'lose', 'half', 'their', 'livestock', 'to', 'the', 'vicious', 'winter', '.', 'They', 'struggle', 'on', '.', 'The', 'last', 'sequence', 'in', 'the', 'film', 'is', 'supposed', 'to', 'be', 'optimistic', ':', 'The', 'birth', 'of', 'a', 'calf', '.', 'Clyde', 'calls', 'Elinore', 'urgently', 'to', 'help', 'him', 'deliver', 'the', 'calf', '.', 'Instead', 'of', 'being', 'head', 'first', ',', 'the', 'calf', 'is', 'in', 'a', 'footling', 'breech', 'presentation', '.', 'He', 'and', 'Elinore', 'must', 'physically', 'pull', 'the', 'calf', 'out', 'of', 'the', 'birth', 'canal', '.', 'There', 'is', 'no', 'CGI', ',', 'animatronics', ',', 'trickery', ',', 'fakery', 'or', 'special', 'effects', ':', 'What', 'you', 'see', 'is', 'what', 'happened', ',', 'folks', ':', 'A', 'calf', 'is', 'born', 'on', 'a', 'bed', 'of', 'straw', 'in', 'a', 'wooden', 'barn', 'by', 'lamplight', '.', 'With', 'that', ',', 'the', 'film', 'does', 'not', 'so', 'much', 'end', 'as', 'simply', 'stop', ',', 'leaving', 'the', 'viewer', 'unsatisfied', ',', 'but', 'after', 'a', 'while', 'you', 'appreciate', 'the', 'film', 'as', 'a', 'whole', ',', 'not', 'just', 'for', 'its', 'ending.<br', '/><br', '/>This', 'little', 'gem', 'rewards', 'patience', 'and', 'thoughtfulness', '.', 'It', 'will', 'be', 'watchable', 'long', 'after', 'most', 'of', 'the', 'films', 'of', 'the', 'last', 'generation', 'have', 'long', 'been', 'forgotten', '.']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EvjEGdQz0EYH",
        "outputId": "3f716a20-a632-42e6-dcb8-3accedefbae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "# Сделаем еще eval\n",
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n",
        "\n",
        "# Сделаем словарь\n",
        "TEXT.build_vocab(train_data, max_size=25000)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
        "\n",
        "print(TEXT.vocab.itos[:10])\n",
        "vars(LABEL.vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n",
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'freqs': Counter({'neg': 8810, 'pos': 8690}),\n",
              " 'itos': ['neg', 'pos'],\n",
              " 'stoi': defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "             {'neg': 0, 'pos': 1}),\n",
              " 'vectors': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xdy-t7zr0EYq",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# собираем батчи так, чтобы в каждом батче были примеры наиболее похожей длины\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "75QoByXO0EYw"
      },
      "source": [
        "## Делаем модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ezPM-mmu0EYy"
      },
      "source": [
        "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment7.png\" width=\"450\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gzRU6UuV0EYz"
      },
      "source": [
        "* В эмбеддер (emb = [torch.nn.Embedding(num_embeddings, embedding_dim)](https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding)) запихиваем тензор размерностью **[sentence length, batch size]**\n",
        "* Эмбеддер возвращает тензор размерностью **[sentence length, batch size, embedding dim]**\n",
        "* RNN (torch.nn.RNN(embedding_dim, hidden_dim)) возвращает 2 тензора, *output* размера [sentence length, batch size, hidden dim] и *hidden* размера [1, batch size, hidden dim]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NrRhJE3z0EY0",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, batch_size,input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.basic_rnn = nn.RNN(self.embedding_dim, self.hidden_dim) \n",
        "        self.clas = nn.Linear(self.hidden_dim, self.output_dim)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "    def init_hidden(self):\n",
        "        # (num_layers, batch_size, n_neurons)\n",
        "        return (torch.zeros(1, self.batch_size, self.hidden_dim))\n",
        "      \n",
        "    def forward (self, text):\n",
        "      \n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        h=self.init_hidden()\n",
        "        \n",
        "        embedded = self.embedding (text)\n",
        "        out, hidden = self.basic_rnn(embedded,h)        \n",
        "\n",
        "        output=self.clas(hidden)\n",
        "        output=self.sigm(output)\n",
        "\n",
        "        return output[0].view(-1,self.output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3l5x_RMAs2Dm",
        "colab": {}
      },
      "source": [
        "input_dim = len(TEXT.vocab.freqs)\n",
        "\n",
        "batch_size=64\n",
        "embedding_dim = 12\n",
        "hidden_dim = 32\n",
        "output_dim = 2\n",
        "N_EPHOCS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1IevFmR40EY4",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model instance\n",
        "model = RNN(batch_size,input_dim, embedding_dim, hidden_dim, output_dim)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy.item()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AwVy7duxswUR",
        "outputId": "137cab71-88d8-4225-e8d3-a4090f9f01c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "for epoch in range(N_EPHOCS):  # loop over the dataset multiple times\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    \n",
        "    # TRAINING ROUND\n",
        "    for i, data in enumerate(train_iterator):\n",
        "         # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # get the inputs\n",
        "        inputs, labels = data.text, data.label.long()\n",
        "        \n",
        "        if(inputs.shape[1]!=batch_size):\n",
        "          continue\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        \n",
        "        out = model(inputs)\n",
        "        \n",
        "\n",
        "        loss = criterion(out, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += get_accuracy(out, labels, BATCH_SIZE)\n",
        "         \n",
        "    model.eval()\n",
        "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f | loss: %.2f' \n",
        "          %(epoch, train_running_loss / i, train_acc/i,loss))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 | Loss: nan | Train Accuracy: 50.16 | loss: nan\n",
            "Epoch:  1 | Loss: nan | Train Accuracy: 49.86 | loss: nan\n",
            "Epoch:  2 | Loss: nan | Train Accuracy: 49.89 | loss: nan\n",
            "Epoch:  3 | Loss: nan | Train Accuracy: 49.92 | loss: nan\n",
            "Epoch:  4 | Loss: nan | Train Accuracy: 49.94 | loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-d2938d9d9014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjx3LxLF_f_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(get_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kOtIp4N_ifL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}