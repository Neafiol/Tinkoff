{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rnn_sentiment_dz.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neafiol/Tinkoff/blob/master/Rnn/Rnn_sentiment_dz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6aMrbyco0EWT",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tn-HHdDC0EXz"
      },
      "source": [
        "# Сентимент анализ \n",
        "\n",
        "пишем сами с нуля\n",
        "\n",
        "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment1.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2OE9H_eM0EX1",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nZOHVoNH0EX4",
        "outputId": "0600a9e0-09a6-4b48-f9af-39fd3f06c2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from torchtext import datasets\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL, root=\"./data\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz:   0%|          | 131k/84.1M [00:00<01:11, 1.18MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 60.9MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Heo6yauU0EX_",
        "outputId": "18a8ab73-5b97-4c91-98e1-8ca2ce19bd17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')\n",
        "\n",
        "print(vars(train_data.examples[0])['text'])\n",
        "len(train_data.examples)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n",
            "['along', 'with', 'it', \"'s\", 'partner', ',', 'this', 'is', 'the', 'greatest', 'piece', 'of', 'animation', 'ever', 'created', '.', 'the', 'images', 'and', 'styles', 'are', 'amazing', ',', 'and', 'match', 'perfectly', 'with', 'the', 'story', 'which', 'is', 'a', 'brilliantly', 'realistic', 'reinterpretation', 'of', 'our', 'own', 'world', ',', 'where', 'is', 'has', 'been', ',', 'and', 'where', 'it', 'could', 'go', '.', 'quite', 'affecting', 'and', 'sometimes', 'painful', 'to', 'watch', ',', 'it', 'it', 'a', 'masterpiece', 'of', 'the', 'visual', 'art', '.']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EvjEGdQz0EYH",
        "outputId": "ba73e2a3-7372-43d5-f12b-ad07619f0927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "# Сделаем еще eval\n",
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n",
        "\n",
        "# Сделаем словарь\n",
        "TEXT.build_vocab(train_data, max_size=25000)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
        "\n",
        "print(TEXT.vocab.itos[:10])\n",
        "vars(LABEL.vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n",
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'freqs': Counter({'neg': 8810, 'pos': 8690}),\n",
              " 'itos': ['neg', 'pos'],\n",
              " 'stoi': defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "             {'neg': 0, 'pos': 1}),\n",
              " 'vectors': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xdy-t7zr0EYq",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# собираем батчи так, чтобы в каждом батче были примеры наиболее похожей длины\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "75QoByXO0EYw"
      },
      "source": [
        "## Делаем модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ezPM-mmu0EYy"
      },
      "source": [
        "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment7.png\" width=\"450\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gzRU6UuV0EYz"
      },
      "source": [
        "* В эмбеддер (emb = [torch.nn.Embedding(num_embeddings, embedding_dim)](https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding)) запихиваем тензор размерностью **[sentence length, batch size]**\n",
        "* Эмбеддер возвращает тензор размерностью **[sentence length, batch size, embedding dim]**\n",
        "* RNN (torch.nn.RNN(embedding_dim, hidden_dim)) возвращает 2 тензора, *output* размера [sentence length, batch size, hidden dim] и *hidden* размера [1, batch size, hidden dim]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NrRhJE3z0EY0",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, batch_size,input_dim, embedding_dim, hidden_dim, output_dim,dropout=0.3):\n",
        "        super().__init__()\n",
        "        \n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.basic_rnn = nn.LSTM(self.embedding_dim, self.hidden_dim) \n",
        "        self.clas = nn.Linear(self.hidden_dim, self.output_dim)\n",
        "        \n",
        "        self.sm = nn.Softmax(dim = 2)\n",
        "        self.dropout = nn.Dropout(dropout) \n",
        "        \n",
        "        \n",
        "    def init_hidden(self):\n",
        "        # (num_layers, batch_size, n_neurons)\n",
        "        return (torch.zeros(1, self.batch_size, self.hidden_dim))\n",
        "      \n",
        "    def forward (self, text):\n",
        "      \n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        h=self.init_hidden()\n",
        "#         print('text: ', text.size())\n",
        "#         print('text: ', text)\n",
        "        embedded = self.embedding (text)\n",
        "        \n",
        "        out, (hidden, c_0) = self.basic_rnn(embedded) \n",
        "        \n",
        "#         print(\"hidden: \", hidden.size())\n",
        "#         print(\"out: \", out.size())\n",
        "        \n",
        "        output=self.dropout(hidden)\n",
        "        output=self.clas(output)\n",
        "\n",
        "        \n",
        "  \n",
        "#         print(output.size())\n",
        "        \n",
        "        \n",
        "        output=self.sm(output)\n",
        "\n",
        "\n",
        "        return output[0].view(-1,self.output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbdyGGEG7Jkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3l5x_RMAs2Dm",
        "colab": {}
      },
      "source": [
        "input_dim = len(TEXT.vocab.freqs)\n",
        "\n",
        "batch_size=64\n",
        "embedding_dim = 12\n",
        "hidden_dim = 32\n",
        "output_dim = 2\n",
        "N_EPHOCS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjvWpbVH3Nix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "213673ff-70f5-4793-b173-edbc7233124d"
      },
      "source": [
        "input_dim"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102341"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1IevFmR40EY4",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model instance\n",
        "model = RNN(batch_size,input_dim, embedding_dim, hidden_dim, output_dim)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy.item()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AwVy7duxswUR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "35e46c99-0bca-4ce1-fecf-fa208eac42e5"
      },
      "source": [
        "for epoch in range(N_EPHOCS):  # loop over the dataset multiple times\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    \n",
        "    # TRAINING ROUND\n",
        "    for i, data in enumerate(train_iterator):\n",
        "         # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # get the inputs\n",
        "        inputs, labels = data.text, data.label.long()\n",
        "        \n",
        "#         print(\"inputs\",inputs.size())\n",
        "        \n",
        "        if(inputs.shape[1]!=batch_size):\n",
        "          continue\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        \n",
        "        out = model(inputs)\n",
        "        \n",
        "\n",
        "        loss = criterion(out, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += get_accuracy(out, labels, BATCH_SIZE)\n",
        "#         break\n",
        "#     break\n",
        "         \n",
        "    model.eval()\n",
        "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f | loss: %.2f' \n",
        "          %(epoch, train_running_loss / i, train_acc/i,loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 | Loss: 0.6938 | Train Accuracy: 49.23 | loss: 0.69\n",
            "Epoch:  1 | Loss: 0.6933 | Train Accuracy: 49.55 | loss: 0.69\n",
            "Epoch:  2 | Loss: 0.6931 | Train Accuracy: 49.93 | loss: 0.69\n",
            "Epoch:  3 | Loss: 0.6955 | Train Accuracy: 49.67 | loss: 0.70\n",
            "Epoch:  4 | Loss: 0.6957 | Train Accuracy: 49.85 | loss: 0.68\n",
            "Epoch:  5 | Loss: 0.6946 | Train Accuracy: 50.10 | loss: 0.70\n",
            "Epoch:  6 | Loss: 0.6935 | Train Accuracy: 49.39 | loss: 0.69\n",
            "Epoch:  7 | Loss: 0.6922 | Train Accuracy: 50.27 | loss: 0.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjx3LxLF_f_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(get_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kOtIp4N_ifL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8ab1d070-1f03-4e9d-a70b-e69c49869a4e"
      },
      "source": [
        "inputs.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjgfCAr34M9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}