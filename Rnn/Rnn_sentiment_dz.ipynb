{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Rnn_sentiment_dz.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neafiol/Tinkoff/blob/master/Rnn/Rnn_sentiment_dz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6aMrbyco0EWT",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tn-HHdDC0EXz"
      },
      "source": [
        "# Сентимент анализ \n",
        "\n",
        "пишем сами с нуля\n",
        "\n",
        "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment1.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2OE9H_eM0EX1",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "device = torch.device('cuda:0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nZOHVoNH0EX4",
        "outputId": "930084b2-07cf-49ac-8f6b-eaead1ff9018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from torchtext import datasets\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL, root=\"./data\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 62.2MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Heo6yauU0EX_",
        "outputId": "2a8d1017-a9d6-4ec2-e480-5db6596cc16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')\n",
        "\n",
        "print(vars(train_data.examples[0])['text'])\n",
        "len(train_data.examples)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n",
            "['Marvelous', 'James', 'Stewart', ',', 'Vera', 'Miles', 'vehicle', '.', 'What', 'makes', 'this', 'historical', 'film', 'dealing', 'with', 'the', 'FBI', 'so', 'good', 'is', 'the', 'family', 'element', 'that', 'is', 'involved', 'during', 'a', '35', 'year', 'career', 'as', 'depicted', 'by', 'Stewart', 'in', 'the', 'film.<br', '/><br', '/>The', 'film', 'shows', 'a', 'history', 'of', 'the', 'great', 'investigatory', 'agency', '.', 'It', 'deals', 'with', 'airplane', 'bomb', 'plots', ',', 'killing', 'off', 'of', 'Indians', 'in', 'Oklahoma', 'for', 'real', 'estate', 'gain', ',', 'fighting', 'organized', 'crime', ',', 'Nazis', 'and', 'Communists', 'in', 'that', 'order', '.', 'The', 'human', 'element', 'is', 'never', 'far', 'behind', 'as', 'Stewart', 'weds', 'Vera', 'Miles', '.', 'They', 'raise', '3', 'children', 'as', 'Miles', \"'\", 'heart', 'goes', 'out', 'each', 'time', 'Stewart', 'goes', 'out', 'on', 'assignment.<br', '/><br', '/>Look', 'for', 'a', 'brief', 'but', 'memorable', 'performance', 'by', 'Murray', 'Hamilton', '.', 'Years', 'later', ',', 'he', 'appeared', 'as', 'Mr.', 'Robinson', 'in', '1967', \"'s\", '\"', 'The', 'Graduate.\"', '<', 'br', '/><br', '/>The', 'film', 'has', 'nothing', 'but', 'praise', 'for', 'J.', 'Edgar', 'Hoover', '.', 'He', 'certainly', 'brought', 'the', 'FBI', 'up', 'to', 'par.<br', '/><br', '/>True', ',', 'this', 'could', 'be', 'viewed', 'as', 'right', '-', 'wing', 'propaganda', ',', 'especially', 'with', 'Stewart', \"'s\", 'real', '-', 'life', 'Republican', 'views', ',', 'but', 'it', \"'s\", 'well', 'done', ',', 'historically', 'informative', ',', 'and', 'the', 'view', 'of', 'the', 'family', 'so', 'well', 'depicted', '.']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EvjEGdQz0EYH",
        "outputId": "32f8508c-4034-417b-93cf-a6eef0822b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "# Сделаем еще eval\n",
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n",
        "\n",
        "# Сделаем словарь\n",
        "TEXT.build_vocab(train_data, max_size=25000)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
        "\n",
        "print(TEXT.vocab.itos[:10])\n",
        "vars(LABEL.vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n",
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'freqs': Counter({'neg': 8810, 'pos': 8690}),\n",
              " 'itos': ['neg', 'pos'],\n",
              " 'stoi': defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "             {'neg': 0, 'pos': 1}),\n",
              " 'vectors': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xdy-t7zr0EYq",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# собираем батчи так, чтобы в каждом батче были примеры наиболее похожей длины\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "75QoByXO0EYw"
      },
      "source": [
        "## Делаем модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ezPM-mmu0EYy"
      },
      "source": [
        "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment7.png\" width=\"450\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gzRU6UuV0EYz"
      },
      "source": [
        "* В эмбеддер (emb = [torch.nn.Embedding(num_embeddings, embedding_dim)](https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding)) запихиваем тензор размерностью **[sentence length, batch size]**\n",
        "* Эмбеддер возвращает тензор размерностью **[sentence length, batch size, embedding dim]**\n",
        "* RNN (torch.nn.RNN(embedding_dim, hidden_dim)) возвращает 2 тензора, *output* размера [sentence length, batch size, hidden dim] и *hidden* размера [1, batch size, hidden dim]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NrRhJE3z0EY0",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, batch_size,input_dim, embedding_dim, hidden_dim, output_dim,dropout=0.3):\n",
        "        super().__init__()\n",
        "        \n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.basic_rnn = nn.LSTM(self.embedding_dim, self.hidden_dim, bidirectional=True) \n",
        "        self.clas = nn.Linear(self.hidden_dim*2, self.output_dim)\n",
        "        \n",
        "        self.sm = nn.Softmax(dim = 1)\n",
        "        self.dropout = nn.Dropout(dropout) \n",
        "        \n",
        "        \n",
        "    def init_hidden(self):\n",
        "        # (num_layers, batch_size, n_neurons)\n",
        "        return (torch.zeros(1, self.batch_size, self.hidden_dim))\n",
        "      \n",
        "    def forward (self, text):\n",
        "      \n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        h=self.init_hidden()\n",
        "#         print('text: ', text.size())\n",
        "#         print('text: ', text)\n",
        "        embedded = self.embedding (text)\n",
        "        \n",
        "        out, (hidden, c_0) = self.basic_rnn(embedded) \n",
        "#         print(\"after LSTM: \", hidden.size())\n",
        "      \n",
        "        result = torch.cat([hidden[-2,:,:],  hidden[-1,:,:]], dim=1)\n",
        "        \n",
        "#         print(\"after concat: \", result.size())\n",
        "#         print(\"out: \", out.size())\n",
        "        \n",
        "        output=self.dropout(result)\n",
        "        output=self.clas(output)\n",
        "#         print(\"after linear: \", output.size())\n",
        "\n",
        "        \n",
        "  \n",
        "#         print(output.size())\n",
        "        \n",
        "        \n",
        "        output=self.sm(output)\n",
        "#         print(\"after Softmax: \", output.size())\n",
        "\n",
        "\n",
        "\n",
        "        return output.view(-1,self.output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3l5x_RMAs2Dm",
        "colab": {}
      },
      "source": [
        "input_dim = len(TEXT.vocab.freqs)\n",
        "\n",
        "batch_size=BATCH_SIZE #64\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "output_dim = 2\n",
        "N_EPHOCS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1IevFmR40EY4",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model instance\n",
        "model = RNN(batch_size,input_dim, embedding_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy.item()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AwVy7duxswUR",
        "outputId": "c92ccb22-27d6-4d2b-f211-e94bc2736b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "for epoch in range(N_EPHOCS):  # loop over the dataset multiple times\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    \n",
        "    # TRAINING ROUND\n",
        "    for i, data in enumerate(train_iterator):\n",
        "         # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # get the inputs\n",
        "        inputs, labels = data.text, data.label.long()\n",
        "        \n",
        "#         print(\"inputs\",inputs.size())\n",
        "        \n",
        "        if(inputs.cpu().shape[1]!=batch_size):\n",
        "#           print(inputs.shape)\n",
        "          break\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        \n",
        "        out = model(inputs)\n",
        "\n",
        "        loss = criterion(out, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += get_accuracy(out, labels, BATCH_SIZE)\n",
        "#         break\n",
        "#     break\n",
        "         \n",
        "    model.eval()\n",
        "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f | loss: %.2f' \n",
        "          %(epoch, train_running_loss / i, train_acc/i,loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 | Loss: 0.6353 | Train Accuracy: 62.99 | loss: 0.52\n",
            "Epoch:  1 | Loss: 0.4903 | Train Accuracy: 81.11 | loss: 0.63\n",
            "Epoch:  2 | Loss: 0.4565 | Train Accuracy: 84.73 | loss: 0.47\n",
            "Epoch:  3 | Loss: 0.4433 | Train Accuracy: 86.11 | loss: 0.39\n",
            "Epoch:  4 | Loss: 0.4305 | Train Accuracy: 87.55 | loss: 0.39\n",
            "Epoch:  5 | Loss: 0.4487 | Train Accuracy: 85.63 | loss: 0.47\n",
            "Epoch:  6 | Loss: 0.4337 | Train Accuracy: 87.16 | loss: 0.47\n",
            "Epoch:  7 | Loss: 0.4366 | Train Accuracy: 86.90 | loss: 0.46\n",
            "Epoch:  8 | Loss: 0.4281 | Train Accuracy: 87.82 | loss: 0.49\n",
            "Epoch:  9 | Loss: 0.4130 | Train Accuracy: 89.38 | loss: 0.53\n",
            "Epoch:  10 | Loss: 0.4326 | Train Accuracy: 87.30 | loss: 0.45\n",
            "Epoch:  11 | Loss: 0.4383 | Train Accuracy: 86.63 | loss: 0.47\n",
            "Epoch:  12 | Loss: 0.4303 | Train Accuracy: 87.54 | loss: 0.45\n",
            "Epoch:  13 | Loss: 0.4421 | Train Accuracy: 86.37 | loss: 0.50\n",
            "Epoch:  14 | Loss: 0.4161 | Train Accuracy: 89.05 | loss: 0.41\n",
            "Epoch:  15 | Loss: 0.4447 | Train Accuracy: 86.16 | loss: 0.41\n",
            "Epoch:  16 | Loss: 0.4255 | Train Accuracy: 88.09 | loss: 0.44\n",
            "Epoch:  17 | Loss: 0.4411 | Train Accuracy: 86.51 | loss: 0.49\n",
            "Epoch:  18 | Loss: 0.4329 | Train Accuracy: 87.32 | loss: 0.48\n",
            "Epoch:  19 | Loss: 0.4356 | Train Accuracy: 87.06 | loss: 0.43\n",
            "Epoch:  20 | Loss: 0.4355 | Train Accuracy: 87.17 | loss: 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}