{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Neafiol/Tinkoff/blob/master/Copy_of_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aMrbyco0EWT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pIQnwJcp0EWa"
   },
   "source": [
    "## Links:\n",
    "* [Colah blog (LSTM/GRU)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "* [PyTorch tutorial - RNN for name classification](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)\n",
    "* [MNIST classification with RNN tutorial](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79)\n",
    "* [Good tutorials about Torch sentiment](https://github.com/bentrevett/pytorch-sentiment-analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNPUnURH0EWb"
   },
   "source": [
    "## Vanilla RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7V_1eJfI0EWc"
   },
   "source": [
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49pfueCC0EWd"
   },
   "source": [
    "$$\\Large h_{i+1} = tanh(W_x \\cdot X_{i+1} + W_y \\cdot h_{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fLASk9EZ0EWe"
   },
   "source": [
    "# RNN intro\n",
    "\n",
    "\n",
    "Давайте разберемся что из себя вообще представляют рекуррентные нейронные сети в самом простом виде.\n",
    "\n",
    "В самом простом виде для одного входного вектора $x_{(t)}$ и одного слоя рекуррентной сети справедливо такое соотношение:\n",
    "\n",
    "$$y_{(t)} = \\phi (x_{(t)}^T \\cdot w_x + y_{(t-1)}^T \\cdot w_y + b)$$\n",
    "\n",
    "где \n",
    "* $x(t)$ -- входной вектор на текущем шаге\n",
    "* $y(t)$ -- выходной вектор на текущем шаге\n",
    "* $w_x$ -- вектор весов нейронов для входа\n",
    "* $w_y$ -- вектор весов нейронов для выхода\n",
    "* $y(t-1)$ -- выходной вектор с прошлого шага. Для шага 0 этот вектор нулевой\n",
    "* $b$ -- байес (bias)\n",
    "* $\\phi$ -- обозначение для функции активации, например ReLU\n",
    "\n",
    "\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" width=\"600\">\n",
    "\n",
    "Есть понятие **hidden_state** ( $h(t)$ ) -- это \"память\" рекуррентной ячейки.\n",
    "\n",
    "В общем случае $h_{(t)} = f(h_{(t-1)}, x_{(t)})$, на выход также $y{(t)} = f(h{(t-1)}, x{(t)})$.\n",
    "\n",
    "\n",
    "### Упрощение формулы\n",
    "\n",
    "Снова немножко математики чтобы привести формулу выше к более удобному виду.\n",
    "\n",
    "Представим, что на вход подается не один вектор $x_{(t)}$, а целый мини-батч размера $m$ таких векторов $X_{(t)}$, соответственно все дальнейшие размышления мы уже производим в матричном виде:\n",
    "\n",
    "$$ Y_{(t)} = \\phi(X_{(t)}^T \\cdot W_x + Y_{(t-1)}^T \\cdot W_y + b) = \\phi([X_{(t)} Y_{(t-1)}] \\cdot W + b) $$\n",
    "где\n",
    "$$ W = [W_x W_y]^T $$\n",
    "\n",
    "*Операция в скобках квадратных -- конкатенация матриц\n",
    "\n",
    "По размерностям:\n",
    "* $Y_{(t)}$ -- матрица [$m$ x n_neurons]\n",
    "* $X_{(t)}$ -- матрица [$m$ x n_features]\n",
    "* $b$ -- вектор длины n_neurons\n",
    "* $W_x$ -- веса между входами и нейронами размерностью [n_features x n_neurons]\n",
    "* $W_y$ -- веса связей с прошлым выходом размерностью [n_neurons x n_neurons]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7sTGvtn0EWf"
   },
   "source": [
    "# RNN from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Oc7NOBN0EWg"
   },
   "source": [
    "### Задание\n",
    "\n",
    "Напишите класс RNN реализующий vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wci_qxB50EWh"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.vx = nn.Linear(input_size,hidden_size)      \n",
    "        self.vh = nn.Linear(hidden_size,hidden_size)        \n",
    "\n",
    "        \n",
    "       \n",
    "\n",
    "    def forward(self, input_data, hidden):\n",
    "      \n",
    "        w=torch.cat([self.vx(input_data),self.vh(hidden)])\n",
    "        w=torch.tanh(w)\n",
    "        return w\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lLrIR_xZ0EWl"
   },
   "outputs": [],
   "source": [
    "input_feature_size = 6\n",
    "hidden_size=5\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "neLd-XbC0EWo"
   },
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=input_feature_size, hidden_size=hidden_size)\n",
    "initial_hidden = rnn.initHidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rk9dNdmb0EWs"
   },
   "outputs": [],
   "source": [
    "input_example = torch.rand([batch_size, input_feature_size])\n",
    "new_hidden = rnn(input_example, initial_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2JA3Wn--0EWx",
    "outputId": "010f3366-7ddb-4107-c24c-b7635f3f72aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(new_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "elrPDC1u0EW4",
    "outputId": "aa430dc2-2a11-4f40-b8b7-9762d42fb52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_hidden:  [[0. 0. 0. 0. 0.]]\n",
      "new_hidden:  [[ 0.13374999 -0.22019383 -0.11869428  0.34385833  0.4082044 ]\n",
      " [-0.10096807  0.36108503  0.22438139  0.36570698  0.35673583]]\n"
     ]
    }
   ],
   "source": [
    "print(\"initial_hidden: \", initial_hidden.numpy())\n",
    "print(\"new_hidden: \", new_hidden.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "hST3qUbj0EW8",
    "outputId": "e7c24aa4-b7be-4f89-cb6d-046eab8d6bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_hidden:  [[ 0.13374999 -0.22019383 -0.11869428  0.34385833  0.4082044 ]\n",
      " [-0.06931694  0.33059952  0.1227747   0.35185146  0.41445634]\n",
      " [ 0.04784166  0.34030536 -0.13984264  0.37678915  0.343393  ]]\n"
     ]
    }
   ],
   "source": [
    "new_hidden = rnn(input_example, new_hidden)\n",
    "print(\"new_hidden: \", new_hidden.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FObA6J1V0EXA"
   },
   "source": [
    "### Задание\n",
    "\n",
    "Модифицировать код так, чтобы на входе можно было подавать батчи размером больше 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oHQSReXF0EXB"
   },
   "source": [
    "# Классификация картинок с RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghnex3nA0EXC"
   },
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/2000/1*wFYZpxTTiXVqncOLQd_CIQ.jpeg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "055M12aU0EXE"
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZcHIgKD0EXH"
   },
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "dYCClnFj0EXI",
    "outputId": "a9988747-b9ab-49e7-ed68-1e082b225c66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:01, 9157811.54it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28881 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 136356.96it/s]           \n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:00, 2223093.59it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 50885.90it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# переводим все в тензоры\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "I-T4VmL50EXM",
    "outputId": "54b53adc-b05d-4eea-9c3c-0742023d0269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.0K\n",
      "drwxr-xr-x 4 root root 4.0K Mar 23 13:02 MNIST\n"
     ]
    }
   ],
   "source": [
    "!ls -lh data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "mKT5MJz90EXQ",
    "outputId": "b9d9f3b7-3a60-478b-a9dc-0d51ceceecf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQIji/wH1PLK1+9zvrQAAAABJREFUNa8GHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cUJU5-pg0EXV"
   },
   "source": [
    "## Как выглядит классификация с RNN в общем виде "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EgWtBdLy0EXX"
   },
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*vhAfRLlaeOXZ-bruv7Ostg.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "80G5_e8R0EXY"
   },
   "outputs": [],
   "source": [
    "class ImageRNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super(ImageRNN, self).__init__()\n",
    "        \n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
    "        \n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        X = X.permute(1, 0, 2) \n",
    "        \n",
    "        self.batch_size = X.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
    "        out = self.FC(self.hidden)\n",
    "        \n",
    "        return out.view(-1, self.n_outputs) # batch_size X n_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7xmJyWpv0EXe"
   },
   "outputs": [],
   "source": [
    "N_STEPS = 28\n",
    "N_INPUTS = 28\n",
    "N_NEURONS = 150\n",
    "N_OUTPUTS = 10\n",
    "N_EPHOCS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "pw4OgN790EXi",
    "outputId": "700beb25-60a6-4b6d-beb8-2a159026ca1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0218,  0.1082, -0.0494, -0.0715, -0.0988,  0.1466, -0.0330, -0.0458,\n",
      "         -0.1293, -0.0547],\n",
      "        [ 0.0280,  0.1114, -0.0571, -0.0529, -0.0989,  0.1360, -0.0210, -0.0434,\n",
      "         -0.1379, -0.0463],\n",
      "        [ 0.0275,  0.1075, -0.0519, -0.0406, -0.1157,  0.1198, -0.0145, -0.0560,\n",
      "         -0.1279, -0.0600],\n",
      "        [ 0.0258,  0.1012, -0.0478, -0.0793, -0.0882,  0.1344, -0.0351, -0.0386,\n",
      "         -0.1279, -0.0454],\n",
      "        [ 0.0260,  0.1097, -0.0463, -0.0381, -0.1223,  0.1202, -0.0128, -0.0552,\n",
      "         -0.1232, -0.0605],\n",
      "        [ 0.0256,  0.1188, -0.0500, -0.0748, -0.0948,  0.1324, -0.0282, -0.0518,\n",
      "         -0.1347, -0.0484],\n",
      "        [-0.0188,  0.0940, -0.0778,  0.0196, -0.1180,  0.1329, -0.0413, -0.0102,\n",
      "         -0.1551, -0.0386],\n",
      "        [ 0.0178,  0.1046, -0.0434, -0.0709, -0.0954,  0.1310, -0.0266, -0.0499,\n",
      "         -0.1260, -0.0493],\n",
      "        [ 0.0202,  0.1084, -0.0566, -0.0345, -0.1122,  0.1261, -0.0170, -0.0562,\n",
      "         -0.1295, -0.0543],\n",
      "        [ 0.0218,  0.1011, -0.0496, -0.0721, -0.0939,  0.1446, -0.0356, -0.0366,\n",
      "         -0.1245, -0.0510]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "model = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "logits = model(images.view(-1, 28,28))\n",
    "print(logits[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g56-Q37g0EXm"
   },
   "source": [
    "## Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZmlA1YkL0EXm"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model instance\n",
    "model = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "pt-wbkrl0EXp",
    "outputId": "50660706-05f1-42da-946f-a80f4353c057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Loss: 0.6886 | Train Accuracy: 77.45\n",
      "Epoch:  1 | Loss: 0.3027 | Train Accuracy: 90.79\n",
      "Epoch:  2 | Loss: 0.2427 | Train Accuracy: 92.62\n",
      "Epoch:  3 | Loss: 0.2081 | Train Accuracy: 93.59\n",
      "Epoch:  4 | Loss: 0.1829 | Train Accuracy: 94.37\n",
      "Epoch:  5 | Loss: 0.1695 | Train Accuracy: 94.78\n",
      "Epoch:  6 | Loss: 0.1499 | Train Accuracy: 95.35\n",
      "Epoch:  7 | Loss: 0.1397 | Train Accuracy: 95.60\n",
      "Epoch:  8 | Loss: 0.1314 | Train Accuracy: 95.87\n",
      "Epoch:  9 | Loss: 0.1291 | Train Accuracy: 95.91\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPHOCS):  # loop over the dataset multiple times\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    # TRAINING ROUND\n",
    "    for i, data in enumerate(trainloader):\n",
    "         # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        model.hidden = model.init_hidden() \n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 28,28) \n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "         \n",
    "    model.eval()\n",
    "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f' \n",
    "          %(epoch, train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZaLB4H-0EXt"
   },
   "source": [
    "### Смотрим что на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQjCQ6ml0EXv",
    "outputId": "7f7972df-b150-4fb6-c50f-817f17df5740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.31\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, 28, 28)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "        \n",
    "print('Test Accuracy: %.2f'%( test_acc/i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tn-HHdDC0EXz"
   },
   "source": [
    "# Сентимент анализ по аналогии\n",
    "\n",
    "пишем сами с нуля\n",
    "\n",
    "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2C5nwpEa0EX0"
   },
   "source": [
    "$~ pip install torchtext\n",
    "\n",
    "$~ python -m spacy download en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OE9H_eM0EX1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy')\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "nZOHVoNH0EX4",
    "outputId": "ab829d51-8138-4b3d-f0a5-ab94e0423e38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz:   0%|          | 147k/84.1M [00:00<01:05, 1.29MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 46.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext import datasets\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL, root=\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "8h_fXXDa0EX8",
    "outputId": "5f90d9e4-6ef9-49c1-ef79-80c0c51f4f66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.7M\n",
      "-rw-r--r-- 1 7297 1000 882K Jun 11  2011 imdbEr.txt\n",
      "-rw-r--r-- 1 7297 1000 827K Apr 12  2011 imdb.vocab\n",
      "-rw-r--r-- 1 7297 1000 4.0K Jun 26  2011 README\n",
      "drwxr-xr-x 4 7297 1000 4.0K Apr 12  2011 \u001b[0m\u001b[01;34mtest\u001b[0m/\n",
      "drwxr-xr-x 5 7297 1000 4.0K Jun 26  2011 \u001b[01;34mtrain\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls -lh data/imdb/aclImdb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Heo6yauU0EX_",
    "outputId": "76d3e63d-5d97-4357-fc4a-e3704ad93172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 25000\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "intpMuB9p31F",
    "outputId": "52589a01-7930-4ee1-de8d-4d00d4e24a47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.dataset.Dataset at 0x7f020bdde160>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "RwpXXx7f0EYD",
    "outputId": "c131158e-ec2b-4424-8b45-41f59e4dbaa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perhaps', 'because', 'I', 'was', 'so', 'young', ',', 'innocent', 'and', 'BRAINWASHED', 'when', 'I', 'saw', 'it', ',', 'this', 'movie', 'was', 'the', 'cause', 'of', 'many', 'sleepless', 'nights', 'for', 'me', '.', 'I', 'have', \"n't\", 'seen', 'it', 'since', 'I', 'was', 'in', 'seventh', 'grade', 'at', 'a', 'Presbyterian', 'school', ',', 'so', 'I', 'am', 'not', 'sure', 'what', 'effect', 'it', 'would', 'have', 'on', 'me', 'now', '.', 'However', ',', 'I', 'will', 'say', 'that', 'it', 'left', 'an', 'impression', 'on', 'me', '...', 'and', 'most', 'of', 'my', 'friends', '.', 'It', 'did', 'serve', 'its', 'purpose', ',', 'at', 'least', 'until', 'we', 'were', 'old', 'enough', 'and', 'knowledgeable', 'enough', 'to', 'analyze', 'and', 'create', 'our', 'own', 'opinions', '.', 'I', 'was', 'particularly', 'terrified', 'of', 'what', 'the', 'newly', '-', 'converted', 'post', '-', 'rapture', 'Christians', 'had', 'to', 'endure', 'when', 'not', 'receiving', 'the', 'mark', 'of', 'the', 'beast', '.', 'I', 'do', \"n't\", 'want', 'to', 'spoil', 'the', 'movie', 'for', 'those', 'who', 'have', \"n't\", 'seen', 'it', 'so', 'I', 'will', 'not', 'mention', 'details', 'of', 'the', 'scenes', ',', 'but', 'I', 'can', 'still', 'picture', 'them', 'in', 'my', 'head', '...', 'and', 'it', \"'s\", 'been', '19', 'years', '.']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rnsn6YLlq4xQ",
    "outputId": "38927261-e5c7-41af-b835-4eb35905b3ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17500"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvjEGdQz0EYH"
   },
   "outputs": [],
   "source": [
    "# Сделаем еще eval\n",
    "import random\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lw0giIPe0EYM"
   },
   "outputs": [],
   "source": [
    "# Сделаем словарь\n",
    "TEXT.build_vocab(train_data, max_size=25000)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "gzE2yU650EYR",
    "outputId": "38227dcd-d547-4917-b9f0-9f7ad013079e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uWelARJ-rgE-",
    "outputId": "a52b7347-b4a2-439a-aa44-c8482c4bfffc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.Vocab at 0x7f01ec34e080>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OU6WAEri0EYV",
    "outputId": "4a07f42f-d917-4a9c-8284-c79fe2457fc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'freqs': Counter({'neg': 8810, 'pos': 8690}),\n",
       " 'itos': ['neg', 'pos'],\n",
       " 'stoi': defaultdict(<function torchtext.vocab._default_unk_index()>,\n",
       "             {'neg': 0, 'pos': 1}),\n",
       " 'vectors': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FU-19gnh0EYa"
   },
   "source": [
    "Почему 25002, а не 25000?\n",
    "Потому что $<unk>$ и $<pad>$\n",
    "\n",
    "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment6.png\" width=\"160\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WQPa1Z70EYb",
    "outputId": "d26cf25f-1c47-4656-9916-98ca3ed77bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 202477), (',', 192116), ('.', 165088), ('a', 109236), ('and', 109177), ('of', 101088), ('to', 93504), ('is', 76396), ('in', 61294), ('I', 54007), ('it', 53323), ('that', 48902), ('\"', 44048), (\"'s\", 43236), ('this', 42364), ('-', 37002), ('/><br', 35684), ('was', 34977), ('as', 30126), ('with', 29740)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lr3mh8zf0EYh"
   },
   "source": [
    "* stoi (string to int)\n",
    "* itos (int to string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jo0S1ekS0EYh",
    "outputId": "20c298f3-b771-41a0-9469-17be7ddb224e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "luy_GhzO0EYm",
    "outputId": "2c3e96ef-2e81-4eb2-9b61-25b2568c6e25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7f020c68e8c8>, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdy-t7zr0EYq"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# собираем батчи так, чтобы в каждом батче были примеры наиболее похожей длины\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 13635
    },
    "colab_type": "code",
    "id": "Ph6Popvl7BH2",
    "outputId": "aaa27cff-fcb4-49ff-8185-650c2e973e63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "for i in train_iterator:\n",
    "  print(i.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "75QoByXO0EYw"
   },
   "source": [
    "## Делаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ezPM-mmu0EYy"
   },
   "source": [
    "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment7.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gzRU6UuV0EYz"
   },
   "source": [
    "* В эмбеддер (emb = [torch.nn.Embedding(num_embeddings, embedding_dim)](https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding)) запихиваем тензор размерностью **[sentence length, batch size]**\n",
    "* Эмбеддер возвращает тензор размерностью **[sentence length, batch size, embedding dim]**\n",
    "* RNN (torch.nn.RNN(embedding_dim, hidden_dim)) возвращает 2 тензора, *output* размера [sentence length, batch size, hidden dim] и *hidden* размера [1, batch size, hidden dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrRhJE3z0EY0"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, batch_size,input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.basic_rnn = nn.RNN(self.embedding_dim, self.hidden_dim) \n",
    "        self.clas = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return torch.zeros(self.batch_size, self.input_dim, embedding_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding (text)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, self.hidden = self.basic_rnn(embedded,self.hidden)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        output=self.clas(output)\n",
    "        output=self.sigm(output)\n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3l5x_RMAs2Dm"
   },
   "outputs": [],
   "source": [
    "input_dim = 911 ??\n",
    "batch_size=64\n",
    "embedding_dim = 12\n",
    "hidden_dim = 32\n",
    "output_dim = 2\n",
    "N_EPHOCS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1IevFmR40EY4"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model instance\n",
    "model = RNN(batch_size,input_dim, embedding_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "AwVy7duxswUR",
    "outputId": "b8825d2a-4d50-489c-d7ab-0c4d794046f0"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-effec0d7dd54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# reset hidden states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RNN' object has no attribute 'init_hidden'"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPHOCS):  # loop over the dataset multiple times\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    # TRAINING ROUND\n",
    "    for i, data in enumerate(train_iterator):\n",
    "         # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        model.hidden = model.init_hidden() \n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels = data.text, data.label\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "         \n",
    "    model.eval()\n",
    "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f' \n",
    "          %(epoch, train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFmel58l70F1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Copy of RNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
